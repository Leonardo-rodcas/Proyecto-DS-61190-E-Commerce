{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "YskaY7jR5jxd",
        "45KoRAYLSbn3",
        "zxvqlJ2iZ8Bd"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/blob/main/Proyecto_EntregaPlus_Comision61190_RodriguezCastilloLeonardo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Presentacion de Proyecto ENTREGA PLUS**"
      ],
      "metadata": {
        "id": "6lbmWPQpa6fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.- Hipótesis.**\n",
        "***Primer Hipóteseis***: La zona geográfica donde se envían los\n",
        "pedidos influye en nuestros indicadores de:\n",
        "* Puntualidad de Entrega de Pedidos\n",
        "* Efectividad de Entrega de Pedidos\n",
        "\n",
        "Con lo cual entendemos que sabiendo donde debemos entregar cada uo de ellos, podemos establecer una probabilidad de NO ENTREGA, que nos va a permitir tomar acciones para que cada pedido con baja probalidad de entrega, sea finalmente entregado en su primer visita\n",
        "\n",
        "***Segunda Hipóteseis***: Los proveedores logísticos pueden ser más fuertes en una zona que en otra"
      ],
      "metadata": {
        "id": "fC1WUEqAbDzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. - Objetivo y alcance.**\n",
        "El Objetivo del proyecto es poder crear un modelo que pueda identificar para cada pedido, si el mismo se va a entregar o no en la primer visita que realice nuestro proveedor logístico."
      ],
      "metadata": {
        "id": "HWEhdmIkbZDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Acquisition**"
      ],
      "metadata": {
        "id": "YskaY7jR5jxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metadata**"
      ],
      "metadata": {
        "id": "45KoRAYLSbn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.- Descripción de los datos.**\n",
        "\n",
        "El set de datos es acerca de pedidos de la empresa EPSILON S.A., los cuales hacen referencia a los detalles para la entrega de los mismos a nuestros clientes.\n",
        "\n",
        "**2.- Detalles generales del dataset**\n",
        "* Cantidad de Registros: 190152\n",
        "* Volumen de Crecimiento Estimado Diario: 5000\n",
        "* Datos del año 2024\n",
        "\n",
        "**3.- Diccionario de datos.**\n",
        "\n",
        "| Columna | Tipo de Dato |\n",
        "|---------|--------------|\n",
        "| Entrega |  int64 |\n",
        "| Fecha Pedido | datetime64 |\n",
        "| Distribuidor | category |\n",
        "| Distribuidor Sigla | category |\n",
        "| Tipo de Distribución Comercial | category |\n",
        "| Codigo Postal | int64 |\n",
        "| Id Provincia | int64 |\n",
        "| Provincia | category |\n",
        "| Localidad | category |\n",
        "| Departamento |category |\n",
        "| Aglomerado |category |\n",
        "| Id Zona Logistica | int64 |\n",
        "| Zona Logistica |category |\n",
        "| Zona E-Commerce |category |\n",
        "| Periodo |category |\n",
        "| Año | int64 |\n",
        "| Mes Sigla |category |\n",
        "| Mes Nombre |category |\n",
        "| Mes Numero | int64 |\n",
        "| Trimestre Sigla |category |\n",
        "| Trimestre Nombre |category |\n",
        "| Trimestre Numero | int64 |\n",
        "| Semestre | int64 |\n",
        "| Año Semana |category |\n",
        "| Dia Semana Sigla |category |\n",
        "| Dia Semana Numero | int64 |\n",
        "| Dia Semana Nombre |category |\n",
        "| Hora Pedido | int64 |\n",
        "| Visita 1 Fecha | datetime64[ns] |\n",
        "| Visita 1 Hora | object |\n",
        "| ID Visita 1 Motivo |category |\n",
        "| Visita 1 Motivo |category |\n",
        "| Dias Primer Visita | int64 |\n",
        "| Flag Visita 1 Puntual |category |\n",
        "| Estado Visita |category |\n",
        "| Estado Distribución |category |\n",
        "| Calidad de la Direccion |category |\n",
        "| Cantidad de Pedidos | int64 |\n",
        "| Visita 1 Puntual | int64 |\n",
        "| Cant. Primera Visita | int64 |\n",
        "| Cant. Vis. y Ent. 1ra Visita | int64 |\n",
        "| Cantidad Celulares | int64 |\n",
        "| Cantidad Accesorios | int64 |\n",
        "| Peso Bruto | float64 |\n",
        "| Valor Total en Pesos | float64 |\n",
        "| Valor Total en Dolares | float64 |\n",
        "| Provincia Sigla | object |\n",
        "| Hora Visita | int64 |"
      ],
      "metadata": {
        "id": "DhBTgO0upzBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importacion de Dataset**"
      ],
      "metadata": {
        "id": "cA4gBiRtbt_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDjHAyfpRktO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Instalación de Librerías\n",
        "!pip install dataprep\n",
        "!pip install chart_studio\n",
        "!pip install mglearn\n",
        "!pip install gapminder\n",
        "#! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
        "\n",
        "# Importación de Librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import matplotlib.animation as animation\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import chart_studio.plotly as py\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import missingno as msno\n",
        "import scipy\n",
        "# La Librería Scipy es exclusiva de datos estadísticos\n",
        "\n",
        "import requests\n",
        "# La librería requests en Python es una herramienta poderosa y popular que se utiliza para realizar solicitudes HTTP de manera sencilla\n",
        "# y eficiente. Permite interactuar con páginas web, APIs RESTful, y otros servicios basados en HTTP\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
        "# La librería warnings en Python se utiliza para gestionar y controlar mensajes de advertencia (warnings) durante la ejecución de un programa.\n",
        "# A diferencia de los errores, que detienen la ejecución del programa, los warnings son mensajes informativos que indican situaciones potencialmente\n",
        "# problemáticas, pero permiten que el programa continúe ejecutándose\n",
        "\n",
        "import mglearn\n",
        "# La librería mglearn (abreviatura de mglearn) es una herramienta complementaria que facilita el aprendizaje y la enseñanza de Machine Learning en Python.\n",
        "# Está diseñada principalmente para ilustrar conceptos básicos de aprendizaje automático de manera visual e intuitiva\n",
        "\n",
        "import graphviz\n",
        "# La librería graphviz en Python se utiliza para trabajar con Graphviz, una herramienta de visualización gráfica que permite crear y\n",
        "# representar grafos dirigidos y no dirigidos. Es especialmente útil para crear diagramas jerárquicos, flujos de trabajo, árboles de decisión,\n",
        "# redes de dependencias y otras estructuras gráficas\n",
        "\n",
        "import folium  #needed for interactive map\n",
        "from folium.plugins import HeatMap\n",
        "# La librería folium en Python se utiliza para crear mapas interactivos de manera sencilla y visualmente atractiva. Es una herramienta ideal para trabajar\n",
        "# con datos geoespaciales y visualizar información geográfica superpuesta en mapas\n",
        "\n",
        "#from ydata_profiling import ProfileReport\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "# La librería IPython.display de Python es un módulo utilizado principalmente en entornos interactivos como Jupyter Notebooks. Su función es proporcionar\n",
        "# herramientas para mostrar salidas de una manera más rica y flexible, como imágenes, gráficos, HTML, audio y más. Esto mejora la experiencia de visualización\n",
        "# y presentación de resultados\n",
        "# La librería display en Python es parte del paquete IPython.display, que proporciona funciones para mostrar objetos de manera interactiva y enriquecida\n",
        "# dentro de entornos como Jupyter Notebook o Google Colab.\n",
        "# Permite mostrar no solo texto, sino también imágenes, gráficos, HTML, Markdown, audio, video y otros tipos de datos de forma estructurada\n",
        "# y visualmente atractiva\n",
        "# La función HTML se usa para mostrar contenido HTML directamente en el cuaderno de Jupyter. Esto es especialmente útil para integrar código HTML en tus\n",
        "# celdas y ver cómo se presenta sin tener que crear archivos externos.\n",
        "\n",
        "from bokeh.io import show, output_file\n",
        "# La librería bokeh.io es parte del ecosistema de Bokeh en Python, una herramienta para crear visualizaciones interactivas de alta calidad que se pueden\n",
        "# integrar fácilmente en aplicaciones web o presentaciones.\n",
        "# Bokeh es especialmente útil cuando se quiere trabajar con gráficos dinámicos y visualizaciones interactivas para la web, como gráficos de líneas, barras,\n",
        "# dispersión, mapas, y más, todo en tiempo real.\n",
        "# Las funciones show y output_file provienen de la librería Bokeh, que se utiliza para crear visualizaciones interactivas en Python. Estas funciones son\n",
        "# clave para mostrar los gráficos creados con Bokeh, ya sea en un navegador web o como parte de un archivo HTML\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "# La librería bokeh.plotting de Bokeh en Python se utiliza para crear visualizaciones interactivas y dinámicas en el navegador web. Permite generar gráficos\n",
        "# y visualizaciones atractivas que los usuarios pueden explorar de manera interactiva, como hacer zoom, mover, o seleccionar puntos en los gráficos.\n",
        "# Bokeh es especialmente útil para proyectos que requieren visualización web o dashboard interactivo.\n",
        "# La función figure de la librería Bokeh en Python es el núcleo para crear gráficos interactivos y personalizados. Bokeh es una biblioteca poderosa para\n",
        "# la visualización de datos, y la función figure actúa como un lienzo donde puedes agregar elementos visuales, como gráficos de líneas, barras, puntos, etc.\n",
        "\n",
        "from bokeh.models import DatetimeTickFormatter\n",
        "# bokeh.models contiene modelos que proporcionan herramientas, widgets y componentes que puedes utilizar para personalizar y mejorar las visualizaciones\n",
        "# en Bokeh.\n",
        "# Estos modelos permiten añadir interactividad, controlar las propiedades visuales de los elementos gráficos, y configurar la forma en que los gráficos\n",
        "# responden a las acciones del usuario.\n",
        "\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "# La librería mlxtend.plotting es parte de mlxtend (machine learning extensions), una biblioteca de Python que proporciona herramientas adicionales para el\n",
        "# análisis y visualización de datos, especialmente orientadas a machine learning y análisis exploratorio. La sublibrería mlxtend.plotting está diseñada para\n",
        "# facilitar la visualización de resultados y modelos de aprendizaje automático, creando gráficos que son útiles tanto para la interpretación de modelos como\n",
        "# para la presentación de resultados\n",
        "\n",
        "from dataprep.eda import create_report\n",
        "# La librería dataprep.eda es parte de la biblioteca dataprep en Python y está diseñada para facilitar el proceso de exploración y análisis de datos. Es una\n",
        "# herramienta muy útil para realizar un análisis exploratorio de datos (EDA) de manera rápida y eficiente, sin necesidad de escribir mucho código.\n",
        "# dataprep.eda automatiza muchas tareas comunes en la exploración de datos y te permite obtener información valiosa sobre tu conjunto de datos con poco esfuerzo\n",
        "\n",
        "from gapminder import gapminder\n",
        "# Gapminder es una biblioteca utilizada para trabajar con el conjunto de datos Gapminder, que contiene información socioeconómica y de salud\n",
        "# de varios países a lo largo del tiempo. Este conjunto de datos es muy popular en análisis de datos, visualización y aprendizaje de estadísticas.\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de Enlaces de los Datasets del Proyecto en Github\n",
        "URL1 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_1_Pedidos_61190.xlsx'\n",
        "URL2 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_2_Pedidos_61190.xlsx'\n",
        "URL3 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_3_Pedidos_61190.xlsx'"
      ],
      "metadata": {
        "id": "VHPOcro3R9zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cremos Dataframes con los enlaces anteriores\n",
        "# A todos los campos los importo como String, para luego convertir particularmente los que no lo sean\n",
        "df_2024_Sem_1 = pd.read_excel(URL1, dtype='str')\n",
        "df_2024_Sem_2 = pd.read_excel(URL2, dtype='str')\n",
        "df_2024_Sem_3 = pd.read_excel(URL3, dtype='str')"
      ],
      "metadata": {
        "id": "Hs2xAAvLQPeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del primer dataframe sea String\n",
        "df_2024_Sem_1.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "acFtVQ__QS9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del segundo dataframe sea String\n",
        "df_2024_Sem_2.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O1hqBkhxQW_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del tercer dataframe sea String\n",
        "df_2024_Sem_3.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OFnA4-bfQZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos Dataframe Auxiliar con datos de Provicias\n",
        "URL3 = 'https://infra.datos.gob.ar/georef/provincias.json'\n",
        "response = requests.get(URL3)\n",
        "datos_json = json.loads(response.text)\n",
        "df_prov = pd.DataFrame.from_dict(datos_json['provincias'])\n",
        "\n",
        "# Renombramos la columna \"Id\" a \"Id Provincia\"\n",
        "df_prov = df_prov.rename(columns={'id': 'Id Provincia'})\n",
        "\n",
        "# Agregamos la columna \"Sigla Provincia\" y le aportamos un valor a cada una\n",
        "df_prov['Provincia Sigla']=\"\"\n",
        "df_prov.loc[df_prov['Id Provincia'] == '02', 'Provincia Sigla'] = 'CABA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '06', 'Provincia Sigla'] = 'BSAS'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '10', 'Provincia Sigla'] = 'CATA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '14', 'Provincia Sigla'] = 'CORD'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '18', 'Provincia Sigla'] = 'CTES'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '22', 'Provincia Sigla'] = 'CHAC'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '26', 'Provincia Sigla'] = 'CHUB'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '30', 'Provincia Sigla'] = 'ERIO'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '34', 'Provincia Sigla'] = 'FORM'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '38', 'Provincia Sigla'] = 'JUJU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '42', 'Provincia Sigla'] = 'PAMP'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '46', 'Provincia Sigla'] = 'RIOJ'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '50', 'Provincia Sigla'] = 'MEND'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '54', 'Provincia Sigla'] = 'MISI'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '58', 'Provincia Sigla'] = 'NEUQ'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '62', 'Provincia Sigla'] = 'RNEG'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '66', 'Provincia Sigla'] = 'SALT'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '70', 'Provincia Sigla'] = 'SJUA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '74', 'Provincia Sigla'] = 'SLUI'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '78', 'Provincia Sigla'] = 'SCRU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '82', 'Provincia Sigla'] = 'SAFE'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '86', 'Provincia Sigla'] = 'SEST'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '90', 'Provincia Sigla'] = 'TUCU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '94', 'Provincia Sigla'] = 'TFUE'\n",
        "\n",
        "# Mostramos resultado\n",
        "df_prov.head(5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2T1fADC8QfuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Wrangling**"
      ],
      "metadata": {
        "id": "zxvqlJ2iZ8Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Concatenado de Dataframes**"
      ],
      "metadata": {
        "id": "2FLyOvICbW5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenamos los 3 Dataframes del año 2024\n",
        "frames = [df_2024_Sem_1, df_2024_Sem_2, df_2024_Sem_3]\n",
        "df_concat = pd.concat(frames)"
      ],
      "metadata": {
        "id": "SGLViFzsQe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merge de Dataframes**"
      ],
      "metadata": {
        "id": "GNedlHmabmXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos Merge entre el Dataframe principal y el de provicias para agregar la columna Sigla de la provincia\n",
        "df = pd.merge(df_concat, df_prov, left_on = \"Id Provincia\", right_on = \"Id Provincia\", how = 'left')\n",
        "df.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3u7t2Ny5QksV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Registros en NaN**"
      ],
      "metadata": {
        "id": "LCjWcduLbtO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos registros NaN en los campos geográficos para que quede constancia de los mismos\n",
        "df_geo = df[['Entrega','Codigo Postal','Provincia','Provincia Sigla']]\n",
        "df_geo.loc[df_geo['Provincia Sigla'].isna()]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I46VaJYkQqpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos registros NaN en todo lo referente a los datos geográficos del Dataframe principal\n",
        "df = df.dropna(subset=['Provincia Sigla'])\n",
        "df.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4hK-DQi-QuSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos los casos que no tienen visitas\n",
        "df_sin_visita = df[['Entrega','Visita 1 Fecha','Estado Visita']]\n",
        "df_sin_visita.loc[df_sin_visita['Visita 1 Fecha'].isna()]"
      ],
      "metadata": {
        "id": "oyowlKUkivWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos registros NaN en todo lo referente a la Primer Visita\n",
        "df = df.dropna(subset=['Visita 1 Fecha'])\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jt8ENCWwjrT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cambio del tipo de datos de las columnas**"
      ],
      "metadata": {
        "id": "C5wvXc-fb2z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiamos el tipo de datos de las columnas que corresponda\n",
        "df = df.astype({\n",
        "    'Entrega': 'int64',\n",
        "    'Distribuidor': 'category',\n",
        "    'Distribuidor Sigla': 'category',\n",
        "    'Centro': 'category',\n",
        "    'Centro Sigla': 'category',\n",
        "    'Centro Tipo': 'category',\n",
        "    'Tipo de Distribución Comercial': 'category',\n",
        "    'Codigo Postal': 'int64',\n",
        "    'Id Provincia': 'int64',\n",
        "    'Provincia': 'category',\n",
        "    'Localidad': 'category',\n",
        "    'Departamento': 'category',\n",
        "    'Aglomerado': 'category',\n",
        "    'Id Zona Logistica': 'int64',\n",
        "    'Zona Logistica': 'category',\n",
        "    'Zona E-Commerce': 'category',\n",
        "    'Periodo': 'category',\n",
        "    'Año': 'int64',\n",
        "    'Mes Sigla': 'category',\n",
        "    'Mes Nombre': 'category',\n",
        "    'Mes Numero': 'int64',\n",
        "    'Trimestre Sigla': 'category',\n",
        "    'Trimestre Nombre': 'category',\n",
        "    'Trimestre Numero': 'int64',\n",
        "    'Semestre': 'int64',\n",
        "    'Año Semana': 'category',\n",
        "    'Dia Semana Sigla': 'category',\n",
        "    'Dia Semana Nombre': 'category',\n",
        "    'Dia Semana Numero': 'int64',\n",
        "    'Hora': 'int64',\n",
        "    'ID Visita 1 Motivo': 'category',\n",
        "    'Visita 1 Motivo': 'category',\n",
        "    'Dias Primer Visita': 'int64',\n",
        "    'Flag Visita 1 Puntual': 'category',\n",
        "    'Estado Visita': 'category',\n",
        "    'Estado Distribución': 'category',\n",
        "    'Calidad de la Direccion': 'category',\n",
        "    'Cantidad de Pedidos': 'int64',\n",
        "    'Visita 1 Puntual': 'int64',\n",
        "    'Cant. Primera Visita': 'int64',\n",
        "    'Cant. Vis. y Ent. 1ra Visita': 'int64',\n",
        "    'Cantidad Celulares': 'int64',\n",
        "    'Cantidad Tarjetas SIMs': 'int64',\n",
        "    'Cantidad Accesorios': 'int64',\n",
        "    'Cantidad Accesorios IOT': 'int64',\n",
        "    'Peso Bruto': 'float64',\n",
        "    'Costo Total de Materiales': 'float64',\n",
        "    'Valor Total USD': 'float64',\n",
        "})\n",
        "\n",
        "df['Fecha Pedido'] = pd.to_datetime(df['Fecha Pedido'])\n",
        "df['Visita 1 Fecha'] = pd.to_datetime(df['Visita 1 Fecha'])"
      ],
      "metadata": {
        "id": "61ld0MqYQzwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Renombramos las columnas**"
      ],
      "metadata": {
        "id": "BRYw6RTlb-9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiamos nombres de las columnas que necesiten ser más claras en lo descriptivo\n",
        "df = df.rename(columns={'Hora': 'Hora Pedido'})\n",
        "df = df.rename(columns={'Costo Total de Materiales': 'Valor Total en Pesos'})\n",
        "df = df.rename(columns={'Valor Total USD': 'Valor Total en Dolares'})\n",
        "df = df.rename(columns={'Semestre': 'Semestre Numero'})"
      ],
      "metadata": {
        "id": "0WDFaPB4Q3pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación de nuevos campos**"
      ],
      "metadata": {
        "id": "zQ2a3vcdcG3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el campo \"Hora Visita\" en formato de 2 dígitos (los 2 de la izquierda del campo \"Visita 1 Hora\")\n",
        "df['Hora Visita'] = df['Visita 1 Hora'].str.slice(0, 2)\n",
        "\n",
        "# Cambiamos a Nan los valores Numeral (\"#\") del campo \"Hora Visita\"\n",
        "df.loc[df['Hora Visita'] == '#', 'Hora Visita'] = np.nan\n",
        "\n",
        "# Cambiamos el tipo de datos de esta nueva columna a \"Int64\"\n",
        "df['Hora Visita'] = df['Hora Visita'].astype('Int64')\n",
        "\n",
        "# Validamos que haya quedado correcto el cambio\n",
        "df[['Entrega','Hora Visita']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J7G6Ra02Q7Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el campo \"Tipo Material\"\n",
        "df['Tipo Material'] = np.nan  # Inicializamos la columna\n",
        "\n",
        "df.loc[(df['Cantidad Celulares'] > 0) & (df['Cantidad Accesorios'] == 0), 'Tipo Material'] = 'Celular'\n",
        "df.loc[(df['Cantidad Celulares'] == 0) & (df['Cantidad Accesorios'] > 0), 'Tipo Material'] = 'Accesorio'\n",
        "df.loc[(df['Cantidad Celulares'] > 0) & (df['Cantidad Accesorios'] > 0), 'Tipo Material'] = 'Celular + Accesorio'"
      ],
      "metadata": {
        "id": "sMobvrq8uJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Borrado de Campos innecesarios**"
      ],
      "metadata": {
        "id": "CD22LepYcMTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos las columnas que no aportan valor al Dataframe\n",
        "df = df.drop(['Canal', 'Subcanal', 'Centro', 'Centro Sigla', 'Centro Tipo', 'Puesto de Expedicion', 'Visita 1 Trackeo', 'Visita 1 Transporte', 'Días contrato primera visita'], axis=1)\n",
        "df = df.drop(['Cantidad Tarjetas SIMs', 'Cantidad Accesorios IOT', 'nombre', 'nombre_completo', 'fuente', 'iso_id', 'iso_nombre'], axis=1)\n",
        "df = df.drop(['Latitud Provincia', 'Longitud Provincia', 'Latitud Departamento', 'Longitud Departamento', 'Latitud Localidad', 'Longitud Localidad'], axis=1)\n",
        "df = df.drop(['centroide', 'categoria', 'Año', 'Cantidad de Pedidos'], axis=1)"
      ],
      "metadata": {
        "id": "GwAc8v9aQ-n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición del Índice"
      ],
      "metadata": {
        "id": "Io7TwgLlZaov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indice del Dataframe Principal\n",
        "df = df.set_index('Entrega')"
      ],
      "metadata": {
        "id": "Q-oAzG3kZjxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos algunas estadísticas del Dataset\n",
        "df.describe().round().T"
      ],
      "metadata": {
        "id": "9wtv4kj7U8S8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Método describe()**\n",
        "En línea general se observan datos acordes sobre todo en los indicadores. Pero debemos revisar lo siguiente:\n",
        "* Días Primer Visita tiene:\n",
        "  * Un mínimo de -1. Estos casos no tienen visitas aún con lo cual se deberían quitar del análisis\n",
        "  * Casos que van entre 10 a 62 días para la primer visita. Se debería asignar la media a todos esos casos\n",
        "* Peso Bruto tiene un mínimo en 0 (cero), lo cual significa que existen algunos registros en cero\n",
        "* Peso Bruto tiene un peso máximo irreal. Debemos detectar y tratar esos registros\n",
        "* Valor Total en Pesos y Valor Total en Dolares tienen un mínimo en 0 (cero), lo cual significa que existen algunos registros en cero\n",
        "* El campo **\"Cant. Primera Visita\"** se puede borrar del Dataset ya que todos los registros estadísticos del mismo han quedado con valor 1 (uno) (media, minimo, maximo, Q1, Q2, Q3)\n",
        "\n",
        "Esto nos permite concluir que tenemos un muy buen dataset, con una alta calidad de datos"
      ],
      "metadata": {
        "id": "wjqdyul0SJRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Peso Bruto Mayor a 200 KG\n",
        "limite_peso_maximo = 200\n",
        "media_peso = df.loc[df['Peso Bruto'] < limite_peso_maximo, 'Peso Bruto'].mean()\n",
        "df.loc[df['Peso Bruto'] > limite_peso_maximo, 'Peso Bruto'] = media_peso"
      ],
      "metadata": {
        "id": "EeGlSaaoHGa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Peso Bruto = 0 (cero)\n",
        "df.loc[df['Peso Bruto'] == 0, 'Peso Bruto'] = media_peso"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bH-rGRUJauD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Valor Total en $ (Pesos Argentinos)\n",
        "media_pesos_ar = df.loc[df['Valor Total en Pesos'] > 0, 'Valor Total en Pesos'].mean()\n",
        "media_pesos_ar\n",
        "df.loc[df['Valor Total en Pesos'] == 0, 'Valor Total en Pesos'] = media_pesos_ar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b9mM7uhrgGMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Valor Total en u$s (Dolares)\n",
        "media_dolares = df.loc[df['Valor Total en Dolares'] > 0, 'Valor Total en Dolares'].mean()\n",
        "df.loc[df['Valor Total en Dolares'] == 0, 'Valor Total en Dolares'] = media_dolares"
      ],
      "metadata": {
        "id": "Yo776f9YiFlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos los pedidos con más de 10 días para su primer visita\n",
        "limite_dias_primer_visita_maximo = 11\n",
        "df.loc[df['Dias Primer Visita'] >= limite_dias_primer_visita_maximo, ['Dias Primer Visita']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4ZPQnqHroii3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Dias Primer Visita\n",
        "media_dias_primer_visita = df.loc[df['Dias Primer Visita'] < limite_dias_primer_visita_maximo, 'Dias Primer Visita'].mean()\n",
        "df.loc[df['Dias Primer Visita'] >= limite_dias_primer_visita_maximo, 'Dias Primer Visita'] = media_dias_primer_visita"
      ],
      "metadata": {
        "id": "1yXoqNHsh_We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrado del Campo \"Cant. Primera Visita\"\n",
        "df = df.drop(['Cant. Primera Visita'], axis=1)"
      ],
      "metadata": {
        "id": "oXlt9VrU3uMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Exploratorio de Datos (EDA)"
      ],
      "metadata": {
        "id": "Z-pMZkLcZUgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos meta información de la estructura del DataFrame\n",
        "df.shape"
      ],
      "metadata": {
        "id": "O9_bZeF9PfM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el Final del Dataset Principal\n",
        "df.tail(5)"
      ],
      "metadata": {
        "id": "I5fiNzVqPfM7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el Comienzo del Dataset Principal\n",
        "df.head(5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tspoc3RiPfM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos las columnas, la cantidad de datos nulos y el tipo de formato de cada columna\n",
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NAQ4Ed59PfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes de analizar los principales estadísticos, verificamos si nuestra estructura de datos es un dataframe\n",
        "type(df)"
      ],
      "metadata": {
        "id": "okHbhdsQPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación Estadisticas Preliminares\n",
        "df.describe().round(2).T\n",
        "\n",
        "# Se han corregido los datos tratados"
      ],
      "metadata": {
        "id": "iLVOpmlHPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contamos la cantidad de numeros 0 (ceros) por columnas\n",
        "nun_missing = (df == 0).sum()\n",
        "print(nun_missing)"
      ],
      "metadata": {
        "id": "O0iBim1BPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contamos la cantidad de Numerales (#) por columnas, ya que este caracter es el que utiliza el sistema de origen para representar los vaores en NULO\n",
        "nun_missing = (df == \"#\").sum()\n",
        "print(nun_missing)"
      ],
      "metadata": {
        "id": "oKm79hT7VzAY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos resumen de Vaores Nulos\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zYLaR92-J1KL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis Preliminar**\n",
        "* No existen valores duplicados ya que el origen de datos nos asegura que por su propia restricción de clave, que esa situación no va a ocurrir. Cabe aclarar que para este Dataset, en el sistema de origen, la clave/Id es el número de Entrega\n",
        "* El Numeral (#), en el sistema de origen de los datos, representa aquellos valores nulos. Por lo visto en este análisis preliminar, los únicos campos con datos nulos son \"Visita 1 Fecha\" y \"Hora Visita\". Es perfecto que eso así sea ya que son pedidos que aún no han sido visitados\n",
        "* Los valores de 0 (cero) en los campos del Dataset, son coherentes al 100% con el valor que representan\n",
        "* El siguiente Gráfico demuestra la gran calidad del dataset"
      ],
      "metadata": {
        "id": "th9lInoiXbW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos los nulos por columna\n",
        "msno.matrix(df, figsize = (20,5))"
      ],
      "metadata": {
        "id": "U51fRN3hqVp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis con gráficas**"
      ],
      "metadata": {
        "id": "UkL7Ml7AYwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Barras de Cantidad de Pedidos por Zona E-Commerce\n",
        "df_zona_agrup = df.groupby('Zona E-Commerce', as_index=False).size()\n",
        "\n",
        "fig = px.bar(\n",
        "    df_zona_agrup,\n",
        "    x='Zona E-Commerce',\n",
        "    y='size',\n",
        "    title='Cantidad de Pedidos x Zona',\n",
        "    labels={'Zona E-Commerce': 'Zona', 'Cantidad de Pedidos': 'Cantidad de Pedidos'},\n",
        "    color='Zona E-Commerce',  # Colorear las barras en función del salario\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    color_discrete_map = {\n",
        "        'AMBA': '#7FD4C1',\n",
        "        'BALA': '#30BFDD',\n",
        "        'CUYO': '#8690FF',\n",
        "        'GBA': '#ACD0F4',\n",
        "        'LINO': '#F7C0BB',\n",
        "        'LISU': '#F8D0BB',\n",
        "        'MEDI': '#F9A0BB',\n",
        "        'NOA': '#D750BA',\n",
        "        'PATAGONIA': '#A2C0BB'\n",
        "\n",
        "        }\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_traces(\n",
        "    textposition='inside',  # Posición de los valores (texto) en las barras\n",
        "    marker_line_color= None,  # Color del borde de las barras\n",
        "    marker_line_width=1.5       # Grosor del borde de las barras\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    #xaxis_title='Categorías',\n",
        "    #yaxis_title='Ventas Totales',\n",
        "    #template='presentation',  # Tema del gráfico\n",
        "    bargap=0.0,  # Espacio entre las barras (0 a 1)\n",
        "    bargroupgap=0.1,  # Espacio entre grupos de barras\n",
        "    xaxis_title=\"Zonas\",\n",
        "    yaxis_title=\"Cantidad\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "98l9okOsZDKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porcentaje de Pedidos por Proveedor Logístico\n",
        "df_proveedor_agrup = df.groupby('Distribuidor Sigla', as_index=False).size()\n",
        "\n",
        "fig = px.pie(\n",
        "    df_proveedor_agrup,\n",
        "    names ='Distribuidor Sigla',\n",
        "    values ='size',\n",
        "    title='Cantidad de Pedidos x Proveedor',\n",
        "    labels={'Distribuidor Sigla': 'Dist', 'Cantidad de Pedidos': 'Cant'},\n",
        "    color='Distribuidor Sigla',  # Colorear las barras en función del salario\n",
        "    #text='Entrega',\n",
        "    width = 600,\n",
        "    height = 400,\n",
        "    color_discrete_map = {\n",
        "        'AND': '#7FD4C1',\n",
        "        'COA': '#30BFDD',\n",
        "        #'C': '#8690FF',\n",
        "        #'D': '#ACD0F4',\n",
        "        #'E': '#F7C0BB'\n",
        "        }\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_traces(\n",
        "    textposition='inside',  # Posición de los valores (texto) en las barras\n",
        "    marker_line_color= None,  # Color del borde de las barras\n",
        "    marker_line_width=1.5       # Grosor del borde de las barras\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    #xaxis_title='Categorías',\n",
        "    #yaxis_title='Ventas Totales',\n",
        "    #template='presentation',  # Tema del gráfico\n",
        "    bargap=0.0,  # Espacio entre las barras (0 a 1)\n",
        "    bargroupgap=0.1  # Espacio entre grupos de barras\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vh_n9Svnd1T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Efectividad de la Primer Visita por Proveedor y Periodo\n",
        "df_efect_prov_periodo_agrup = df.groupby(['Distribuidor Sigla','Periodo']).agg(\n",
        "    Cantidad_Pedidos = ('Fecha Pedido', 'count'),\n",
        "    Cantidad_Pedidos_Efectivos = ('Cant. Vis. y Ent. 1ra Visita', \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "df_efect_prov_periodo_agrup['Efectividad'] = df_efect_prov_periodo_agrup['Cantidad_Pedidos_Efectivos']/df_efect_prov_periodo_agrup['Cantidad_Pedidos']\n",
        "\n",
        "fig = px.line(\n",
        "    df_efect_prov_periodo_agrup,\n",
        "    x = \"Periodo\",\n",
        "    y = \"Efectividad\",\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    text = df_efect_prov_periodo_agrup[\"Efectividad\"].apply(lambda x: f\"{x:.1%}\"),\n",
        "    color='Distribuidor Sigla',\n",
        "    labels={'Efectividad': \"% Efectividad\", \"Periodo\": \"Mes\"}\n",
        "    )\n",
        "\n",
        "fig.update_traces(\n",
        "    mode=\"lines+markers+text\",\n",
        "    textposition=\"top center\"\n",
        "    )\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Efectividad de la Primer Visita por Proveedor y Zona\n",
        "df_efect_prov_zona_agrup = df.groupby(['Distribuidor Sigla','Zona E-Commerce']).agg(\n",
        "    Cantidad_Pedidos_2 = ('Fecha Pedido', 'count'),\n",
        "    Cantidad_Pedidos_Efectivos_2 = ('Cant. Vis. y Ent. 1ra Visita', \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "df_efect_prov_zona_agrup['Efectividad'] = df_efect_prov_zona_agrup['Cantidad_Pedidos_Efectivos_2']/df_efect_prov_zona_agrup['Cantidad_Pedidos_2']\n",
        "\n",
        "fig2 = px.line(\n",
        "    df_efect_prov_zona_agrup,\n",
        "    x = \"Zona E-Commerce\",\n",
        "    y = \"Efectividad\",\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    text = df_efect_prov_zona_agrup[\"Efectividad\"].apply(lambda x: f\"{x:.1%}\"),\n",
        "    color='Distribuidor Sigla',\n",
        "    labels={'Efectividad': \"% Efectividad\", \"Periodo\": \"Mes\"}\n",
        "    )\n",
        "\n",
        "fig2.update_traces(\n",
        "    mode=\"lines+markers+text\",\n",
        "    textposition=\"top center\"\n",
        "    )\n",
        "\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "JP73ILJvnljg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones EDA**\n",
        "Se comprueban ambas hipótesis planteadas al principio:\n",
        "* *Hipótesis 1:* La Zona Geográfica afecta a los indicadores de la Primer Visita. Por ejemplo:\n",
        "  * Se puede observar claramente la baja performance en AMBA de ambos proveedores\n",
        "  * También se observa como los dos proveedores mejoran sus números distribuyendo en la zona BALA (Buenos Aires - La Pampa)\n",
        "  * Llama también la atención que el proveedor de peor desempeño, tiene el mejor indicador de todos en la Zona GBA (Gran Buenos Aires)\n",
        "\n",
        "* *Hipótesis 2:* Los proveedores claramente tienen un desempeño distinto según las zonas\n",
        "  * Andreani tiene un comportamiento más estable/predecible a nivel nacional, incluso con el atenuante de tener un mayor volumen para distribuir\n",
        "  * Correo Argentino tiene números muchos más bajos, pero a favor de ellos se observa un crecimiento bastante sostenido a lo largo del año"
      ],
      "metadata": {
        "id": "xOhy39uh_b01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Estadístico de datos"
      ],
      "metadata": {
        "id": "tz0Q3mrnZqhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_mensuales =df.groupby(df['Fecha Pedido'].dt.to_period('M')).size()\n",
        "pedidos_mensuales.plot.line()"
      ],
      "metadata": {
        "id": "HWL8V3rzUKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis con scipy.stats\n",
        "Es un módulo de SciPy que proporciona herramientas estadísticas muy completas para análisis de datos. Estas funciones abarcan estadística descriptiva, distribución de probabilidad, pruebas de hipótesis, estadísticas no paramétricas, y mucho más"
      ],
      "metadata": {
        "id": "tKHqTOXq55TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe es un resumen estadístico (número de elementos, media, desviación estándar, etc.).\n",
        "scipy.stats.describe(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "MzTNJW2fOQLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desvío Estandar: El desvío estándar es una medida estadística que indica cuánto se desvían, en promedio, los valores de\n",
        "# un conjunto de datos respecto a su media. En otras palabras, muestra la dispersión o variabilidad de los datos. Es una de\n",
        "# las métricas más comunes para evaluar la dispersión de un conjunto de datos y se expresa en las mismas unidades que los\n",
        "# datos originales\n",
        "scipy.stats.tstd(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "s-g6tXc4DHTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media Geométrica: Calcula la media geométrica, útil cuando los datos representan tasas de cambio o proporciones\n",
        "scipy.stats.gmean(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "Tpj1Zwi5PeqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media Armónica: Calcula la media armónica, ideal para datos en los que las tasas o razones son relevantes.\n",
        "scipy.stats.hmean(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "ebnuNIV_PjeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media recortada: sirve para calcular la media truncada (o media recortada) de un conjunto de datos. Es una medida\n",
        "# estadística que calcula la media de los datos después de eliminar un porcentaje determinado de valores extremos (tanto\n",
        "# los más bajos como los más altos) del conjunto. Esto es útil para reducir el efecto de valores atípicos o extremos sobre\n",
        "# el promedio\n",
        "scipy.stats.trim_mean(pedidos_mensuales,0.1)"
      ],
      "metadata": {
        "id": "HB46A1Z_P41n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moda de los datos: Encuentra el valor o valores que más se repiten en los datos\n",
        "scipy.stats.mode(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "t1u32K9nP6Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficiente de variacion: El coeficiente de variación (CV) es una medida de dispersión relativa que expresa la\n",
        "# desviación estándar como un porcentaje de la media. Se utiliza para comparar la variabilidad entre diferentes conjuntos\n",
        "# de datos, incluso si las magnitudes de las medias son muy diferentes.\n",
        "scipy.stats.variation(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "YELeNp1hOVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango intercuartílico: Calcula la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1), mostrando la\n",
        "# amplitud de los valores centrales del 50% de los datos\n",
        "scipy.stats.iqr(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "GUPNNItjOXKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculo del Error estandar de la media: Este valor cuantifica cuánto puede variar la media muestral con respecto a la\n",
        "# media verdadera de la población\n",
        "scipy.stats.sem(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "Xvy0_vqVZoEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficiente de asimetría: Mide la asimetría de una distribución de datos en torno a su media\n",
        "scipy.stats.skew(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "aigWj9BmOcxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Curtosis de los datos: Mide la \"apuntamiento\" de la distribución en comparación con una normal\n",
        "scipy.stats.kurtosis(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "mwjQKEj_RBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análsis Univariado"
      ],
      "metadata": {
        "id": "hteUic0rZ1a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "pjsrarIJdeNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = [\n",
        "    'Fecha Pedido', 'Hora Pedido', 'Periodo',\n",
        "    'Mes Numero', 'Trimestre Numero', 'Dias Primer Visita',\n",
        "    'Peso Bruto', 'Valor Total en Pesos', 'Valor Total en Dolares',\n",
        "    ]\n",
        "columns = 3\n",
        "filas = len(variables)\n",
        "fig, axes = plt.subplots(len(variables) //columns, columns, figsize=(30,30))\n",
        "\n",
        "for current_idx, variable in enumerate(variables):\n",
        "    i = current_idx // columns\n",
        "    j = current_idx % columns\n",
        "    sns.histplot(df[variable], ax=axes[i][j], kde=True)\n",
        "    axes[i][j].set_title(variable)\n",
        "    axes[i][j].set_xlabel(\"\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Implementación en Ploty\n",
        "# Funciona pero no se ve muy claro. Revisar!!!\n",
        "\n",
        "#fig = make_subplots(rows=filas //columns, cols=columns)\n",
        "#\n",
        "#for current_idx, variable in enumerate(variables):\n",
        "#    i = current_idx // columns\n",
        "#    j = current_idx % columns\n",
        "#    fig.add_trace(\n",
        "#      go.Histogram(x=df[variables], name=variable),\n",
        "#      row=i+1, col=j+1\n",
        "#    )\n",
        "#fig.update_layout(\n",
        "#    title=\"Analisis Univariado con Histogramas\",\n",
        "#    width = 1000,\n",
        "#    height = 300 * filas\n",
        "#)\n",
        "#fig.show()"
      ],
      "metadata": {
        "id": "DTgXRyZkmigU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las mayoría de las distribuciones anteriores tienen variables categóricas, más alla de que sean números enteros (\"Fecha Pedido\", \"Mes Numero\", etc).\n",
        "\n",
        "Las que podemos utilizar y que sean representativas son \"Dias Primera Visita\", Peso Bruto\", \"Valor Total en Pesos\" y \"Valor Total en Dolares\""
      ],
      "metadata": {
        "id": "680wAoM4S3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia',\n",
        "    y='Peso Bruto',\n",
        "    color = 'Provincia',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Peso Bruto por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "r3peGSn16QXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia',\n",
        "    y='Valor Total en Pesos',\n",
        "    color = 'Provincia',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Pesos por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aW1rrFXpBuPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia',\n",
        "    y='Valor Total en Dolares',\n",
        "    color = 'Provincia',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Dolares por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jYR9UvRzFrAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Peso Bruto',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Peso Bruto por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "9xm-8EsJH4io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Valor Total en Pesos',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Pesos por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aFkCgW87RKI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Valor Total en Dolares',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Dolares por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1JhRbFrsRp-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "De los boxplots analizados, vemos muchos outliers, y la conclusión es que esa situación se da porque hay distintos tipos de materiales. Para lograr gráficas con menos Outliers, se deberían separar:\n",
        "* Los pedidos que solo tienen **TELEFONOS**\n",
        "* Los pedidos que solo tienen **ACCESORIOS**\n",
        "* Los pedidos que tienen **TELEFONOS** y **ACCESORIOS** a la vez"
      ],
      "metadata": {
        "id": "D--utYKeUDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análsis Bivariado"
      ],
      "metadata": {
        "id": "hGeHgKcIZ7zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "3KMA-FRWd2tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(\n",
        "    df,\n",
        "    x='Valor Total en Dolares',\n",
        "    y='Valor Total en Pesos',\n",
        "    color='Distribuidor',\n",
        "    size='Peso Bruto',\n",
        "    hover_data=['Valor Total en Pesos']\n",
        ")"
      ],
      "metadata": {
        "id": "WEvisbDgY-s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_spearman = df.corr(method=\"spearman\")\n",
        "corr_spearman"
      ],
      "metadata": {
        "id": "VjX6-kcDA4rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "\n",
        "sns.heatmap(\n",
        "    df.corr(method='spearman'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")\n"
      ],
      "metadata": {
        "id": "-UqgAb1qV8CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_pearson = df.corr(method=\"pearson\")\n",
        "corr_pearson"
      ],
      "metadata": {
        "id": "0RdI9b6OHNX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "sns.heatmap(\n",
        "    df.corr(method='pearson'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")"
      ],
      "metadata": {
        "id": "Fg_6KgpINXmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_kendall = df.corr(method=\"kendall\")\n",
        "corr_kendall"
      ],
      "metadata": {
        "id": "hwF31QWuHnuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "\n",
        "sns.heatmap(\n",
        "    df.corr(method='kendall'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")"
      ],
      "metadata": {
        "id": "uKprn0WEWpA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "* Se observa alta correlación entre las distintas clasificaciones de fecha (\"Mes Numero\", \"Trimestre Número\" y \"Semestre\").\n",
        "* Se observa también una muy fuerte correlación entre el valor de cada \"Entrega\" en Pesos Argentinos y Dólares. Esto si se puede ver como algo causal, ya que a mayor cantidad de pesos, siempre vamos a poder convertir una mayor cantidad de Dólares\n",
        "* Se observa una correlación intermedia o moderada entre el \"cantidad de Celulares\" de las \"Entregas\" y el \"Peso Bruto\", \"Valor Total en Pesos\" y \"Valor Total en Dolares\" que hay en cada una de ellas\n",
        "* Las correlaciones más débiles se da entre \"Días Primera Visita\" y \"Puntualidad Primera Visita\". Eso es totalmente lógico, porque mientras más días se tarda en visitar un cliente, menos probabilidad existe de que la puntualidad se cumpla\n",
        "* También existe una correlación muy débil entre la \"Cantidad de Celulares\" y la \"Cantidad de Accesorios\"\n"
      ],
      "metadata": {
        "id": "13YUHv9gcZDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis Multivariado"
      ],
      "metadata": {
        "id": "8dvaha2faAUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "ntmOfduRv5Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=120)\n",
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HKchv9fPv1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingeniería de atributos"
      ],
      "metadata": {
        "id": "oah9GldXaaiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoder\n",
        "Utilizamos One Hot Encoder para los campos cuya variable categórica tiene hasta 4 valores posible"
      ],
      "metadata": {
        "id": "27klMKnHrL7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el codificador OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)  # sparse=False para devolver una matriz densa\n",
        "\n",
        "# Seleccionar las columnas a transformar\n",
        "columns_to_encode = ['Distribuidor', 'Tipo de Distribución Comercial', 'Zona E-Commerce', 'Estado Visita', 'Estado Distribución', 'Tipo Material']\n",
        "\n",
        "# Ajustar y transformar las columnas categóricas\n",
        "encoded_data = encoder.fit_transform(df[columns_to_encode])\n",
        "\n",
        "# Crear un DataFrame con los resultados de One Hot Encoding\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(columns_to_encode))\n",
        "\n",
        "# Nos aseguramos que ambos Dataframe tengan el mismo Indice\n",
        "encoded_df.index = df.index\n",
        "\n",
        "# Unir el DataFrame original con las columnas codificadas\n",
        "df_encoded = pd.concat([df, encoded_df], axis=1).drop(columns=columns_to_encode)"
      ],
      "metadata": {
        "id": "meapmAaga8mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoder\n",
        "Utilizamos Label Encoder para las variables categóricas que tienen más de 4 clasificaciones"
      ],
      "metadata": {
        "id": "PCRll6Eo4Lnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un diccionario para almacenar los LabelEncoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Aplicamos LabelEncoder a cada columna de interés\n",
        "for column in ['Localidad', 'Departamento', 'Aglomerado', 'ID Visita 1 Motivo']:\n",
        "    le = LabelEncoder()  # Creamos un LabelEncoder para cada columna\n",
        "    df_encoded[column] = le.fit_transform(df_encoded[column])  # Transformamos la columna\n",
        "    label_encoders[column] = le  # Guardamos el LabelEncoder para uso futuro"
      ],
      "metadata": {
        "id": "5FS1Nd5qrqPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ordinal Encoding\n",
        "Utilizamos Ordinal Encoding porque tenemos un campo que tiene logica ordinal. A priori, el orden debe ser alfabético descendiente\n"
      ],
      "metadata": {
        "id": "AgEiWdNv-Gp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el orden de las categorías\n",
        "orden_calidad = [['#', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A']]\n",
        "\n",
        "# Crear y aplicar el OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder(categories=orden_calidad)\n",
        "df_encoded['Calidad de la Direccion Codificada'] = ordinal_encoder.fit_transform(df_encoded[['Calidad de la Direccion']])"
      ],
      "metadata": {
        "id": "l6bZlrl4-mM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento y Testeo\n",
        "Nuestro Dataset cuenta con la variable a predecir la cual es \"Cant. Vis. y Ent. 1ra Visita\". Esta variable solo tiene como valores 0 y 1. Detalles:\n",
        "* 0 = No Entregada\n",
        "* 1 = Entregada"
      ],
      "metadata": {
        "id": "NYewbqv_anWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos Lista de columnas para seleccionar las que van a ser evaluadas en el modelo\n",
        "df_encoded.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Lu8zxbT2P8_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos X\n",
        "X = df_encoded[['Codigo Postal', 'Id Provincia', 'Localidad', 'Departamento', 'Aglomerado', 'Id Zona Logistica',\n",
        "       'Mes Numero', 'Trimestre Numero', 'Semestre Numero', 'Dia Semana Numero', 'Hora Pedido', 'Cantidad Celulares',\n",
        "       'Cantidad Accesorios', 'Peso Bruto', 'Valor Total en Pesos', 'Valor Total en Dolares', 'Distribuidor_Correo Andreani',\n",
        "       'Distribuidor_Correo Argentino',        'Tipo de Distribución Comercial_Pedido Combinado',\n",
        "       'Tipo de Distribución Comercial_Pedido Multiple', 'Tipo de Distribución Comercial_Pedido Simple',\n",
        "       'Zona E-Commerce_#', 'Zona E-Commerce_AMBA', 'Zona E-Commerce_BALA', 'Zona E-Commerce_CUYO', 'Zona E-Commerce_GBA',\n",
        "       'Zona E-Commerce_LINO', 'Zona E-Commerce_LISU', 'Zona E-Commerce_MEDI', 'Zona E-Commerce_NOA',\n",
        "       'Zona E-Commerce_PATAGONIA', 'Tipo Material_Accesorio', 'Tipo Material_Celular', 'Tipo Material_Celular + Accesorio',\n",
        "       'Calidad de la Direccion Codificada']]\n",
        "X.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YqSU3R8nFjqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos y\n",
        "y = df_encoded['Cant. Vis. y Ent. 1ra Visita'].values\n",
        "y"
      ],
      "metadata": {
        "id": "d0-d482lGk2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)#test depende del tamaño del dataset en general, semilla de donde arranca"
      ],
      "metadata": {
        "id": "UJsrEI-KseCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbol de decisión"
      ],
      "metadata": {
        "id": "UeLA4NjhZVD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos la profundidad optima\n",
        "param_grid = {'max_depth': range(1, 12)}\n",
        "\n",
        "# Configurar la búsqueda en rejilla\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Métrica a optimizar\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Ejecutar la búsqueda\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir el mejor valor de max_depth\n",
        "print(f\"Profundidad óptima: {grid_search.best_params_['max_depth']}\")"
      ],
      "metadata": {
        "id": "xAOH3BqANuar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_tree = DecisionTreeClassifier(max_depth= 5)"
      ],
      "metadata": {
        "id": "-CHzyVWxpUM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "clf_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FOfy-1vHqo28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafico del Arbol de Decisión\n",
        "fig = plt.figure(figsize=(12,10))\n",
        "plot_tree(clf_tree,\n",
        "          feature_names = X.columns,\n",
        "          filled = True,\n",
        "          rounded = True,\n",
        "          precision = 3,\n",
        "          class_names = True\n",
        "          )"
      ],
      "metadata": {
        "id": "n6rHRxN0tL7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "tree_pred = clf_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "tINEUGvL3Bdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_tree = accuracy_score(y_test, tree_pred)#comparo son los datos de y test contra los predichos #score\n",
        "print(f'La exactitud (accuracy) obtenido es de: {accuracy_tree}')"
      ],
      "metadata": {
        "id": "y6j95xe43is7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realizaron distintas pruebas y el accuracy daba 100%. Y leyendo como se ha resuelto el árbol de decisión, concluimos que se deben retirar las siguientes variables:\n",
        "* La variable **\"Estado Distribución\"** y **\"Estado Visita\"** muy probablemente se deben retirar del análisis y eso sería lógico, porque al momento que se realice la predicción, el estado de la entrega siempre va a ser **\"No Entregada\"**\n",
        "* La variable **\"Dias Primera Visita\"**. Al principio del análisis el valor de la misma siempre va a ser 0 (cero)\n",
        "* La variable **\"Id Visita 1 Motivo\"** al principio, siempre va a ser un valor nulo\n",
        "* La variable **\"Visita 1 Puntual\"** al principio, siempre va a ser un 0 (cero = no puntual)"
      ],
      "metadata": {
        "id": "4QK_40-p4Rvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística\n"
      ],
      "metadata": {
        "id": "qE5lPoSqFl2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_reg_log=LogisticRegression()"
      ],
      "metadata": {
        "id": "bwwv2Mr3S1Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=45)\n",
        "clf_reg_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nCrOoSSyS9M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "y_pred = clf_reg_log.predict(X_test)\n",
        "accuracy_reg_log = clf_reg_log.score(X_test,y_test)\n",
        "print(f'La exactitud (accuracy) obtenido es de: {accuracy_reg_log}')"
      ],
      "metadata": {
        "id": "MuteWwfNXn7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión\n",
        "confusion_matrix(y_test,y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_reg_log.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t9SYT5akXxrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ramdom Forest"
      ],
      "metadata": {
        "id": "LuOhBppy8zV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_forest = RandomForestClassifier(random_state=42, n_estimators=50)\n",
        "clf_forest.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9jpQOOWtTDr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "y_pred = clf_forest.predict(X_test)\n",
        "accuracy_forest = clf_forest.score(X_test,y_test)\n",
        "print(f'La exactitud (accuracy) obtenido es de: {accuracy_forest}')"
      ],
      "metadata": {
        "id": "J3aDqRofT2qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación del Modelo"
      ],
      "metadata": {
        "id": "zSoeO4nDawAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización del Modelo"
      ],
      "metadata": {
        "id": "VbM0mBO2bDSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble"
      ],
      "metadata": {
        "id": "oJbx8rFda5M6"
      }
    }
  ]
}