{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "YskaY7jR5jxd",
        "45KoRAYLSbn3",
        "zxvqlJ2iZ8Bd"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/blob/main/Proyecto_EntregaPlus_Comision61190_RodriguezCastilloLeonardo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Presentacion de Proyecto ENTREGA PLUS**"
      ],
      "metadata": {
        "id": "6lbmWPQpa6fV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.- Hipótesis.**\n",
        "***Primer Hipótesis***: La zona geográfica donde se envían los\n",
        "pedidos influye en nuestros indicadores de:\n",
        "* Puntualidad de Entrega de Pedidos\n",
        "* Efectividad de Entrega de Pedidos\n",
        "\n",
        "Con lo cual entendemos que sabiendo donde debemos entregar cada uo de ellos, podemos establecer una probabilidad de NO ENTREGA, que nos va a permitir tomar acciones para que cada pedido con baja probalidad de entrega, sea finalmente entregado en su primer visita\n",
        "\n",
        "***Segunda Hipóteseis***: Los proveedores logísticos pueden ser más fuertes que su competidor en una determinada zona, y el otro, en otra\n",
        "\n",
        "***Tercer Hipóteseis***: Mejorar nuestros indicadores implica no solo una excelencia para la experiancia global del cliente, sino que tambien un ahorro enorme a nivel presupuestario\n"
      ],
      "metadata": {
        "id": "fC1WUEqAbDzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. - Objetivo y alcance.**\n",
        "El Objetivo del proyecto es poder crear un modelo que pueda identificar para cada pedido, si el mismo se va a entregar o no en la primer visita que realice nuestro proveedor logístico.\n",
        "\n",
        "**Aclaración:** el proyecto tiene 3 etapas en total, pero nuestro alcance implica participación muy activa en las primeras 2:\n",
        "* **ETAPA 1:** Estudio de los datos\n",
        "* **ETAPA 2:** Desarrollo del Modelo de Machine Learning\n",
        "* **ETAPA 3:** Integración con proveedores Logísticos"
      ],
      "metadata": {
        "id": "HWEhdmIkbZDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Acquisition**"
      ],
      "metadata": {
        "id": "YskaY7jR5jxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metadata**"
      ],
      "metadata": {
        "id": "45KoRAYLSbn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.- Descripción de los datos.**\n",
        "\n",
        "El set de datos es acerca de pedidos de la empresa EPSILON S.A., los cuales hacen referencia a los detalles para la entrega de los mismos a nuestros clientes.\n",
        "\n",
        "**2.- Detalles generales del dataset**\n",
        "* Cantidad de Registros: 190152\n",
        "* Volumen de Crecimiento Estimado Diario: 5000\n",
        "* Datos del año 2024\n",
        "\n",
        "**3.- Diccionario de datos.**\n",
        "\n",
        "| Columna | Tipo de Dato | Tipo de Variable |\n",
        "|---------|--------------|--------------|\n",
        "| Entrega |  int64 | Clave Primeria (index) |\n",
        "| Fecha Pedido | datetime64 | Temporal |\n",
        "| Distribuidor | category | Categórica Nominal |\n",
        "| Distribuidor Sigla | category | Categórica Nominal |\n",
        "| Tipo de Distribución Comercial | category | Categórica Nominal |\n",
        "| Codigo Postal | int64 | Categórica Nominal |\n",
        "| Id Provincia | int64 | Categórica Nominal |\n",
        "| Provincia | category | Categórica Nominal |\n",
        "| Localidad | category | Categórica Nominal |\n",
        "| Departamento |category | Categórica Nominal |\n",
        "| Aglomerado |category | Categórica Nominal |\n",
        "| Id Zona Logistica | int64 | Categórica Nominal |\n",
        "| Zona Logistica |category | Categórica Nominal |\n",
        "| Zona E-Commerce |category | Categórica Nominal |\n",
        "| Periodo |category | Categórica Nominal |\n",
        "| Año | int64 | Categórica Nominal |\n",
        "| Mes Sigla |category | Categórica Nominal |\n",
        "| Mes Nombre |category | Categórica Nominal |\n",
        "| Mes Numero | int64 | Categórica Nominal |\n",
        "| Trimestre Sigla |category | Categórica Nominal |\n",
        "| Trimestre Nombre |category | Categórica Nominal |\n",
        "| Trimestre Numero | int64 | Categórica Nominal |\n",
        "| Semestre | int64 | Categórica Nominal |\n",
        "| Año Semana |category | Categórica Nominal |\n",
        "| Dia Semana Sigla |category | Categórica Nominal |\n",
        "| Dia Semana Numero | int64 | Categórica Nominal |\n",
        "| Dia Semana Nombre |category | Categórica Nominal |\n",
        "| Hora Pedido | int64 | Categórica Nominal |\n",
        "| Visita 1 Fecha | datetime64[ns] | Temporal |\n",
        "| Visita 1 Hora | object | Temporal |\n",
        "| ID Visita 1 Motivo |category | Categórica Nominal |\n",
        "| Visita 1 Motivo |category | Categórica Nominal |\n",
        "| Dias Primer Visita | int64 | Categórica Ordinal |\n",
        "| Flag Visita 1 Puntual |category | Categórica Nominal |\n",
        "| Estado Visita |category | Categórica Nominal |\n",
        "| Estado Distribución |category | Categórica Nominal |\n",
        "| Calidad de la Direccion |category | Categórica Nominal |\n",
        "| Cantidad de Pedidos | int64 | Categórica Nominal |\n",
        "| Visita 1 Puntual | int64 | Categórica Nominal |\n",
        "| Cant. Primera Visita | int64 | Categórica Nominal |\n",
        "| Cant. Vis. y Ent. 1ra Visita | int64 | Categórica Nominal |\n",
        "| Cantidad Celulares | int64 | Numérica Discreta |\n",
        "| Cantidad Accesorios | int64 | Numérica Discreta |\n",
        "| Peso Bruto | float64 | Numérica Contínua |\n",
        "| Valor Total en Pesos | float64 | Numérica Contínua |\n",
        "| Valor Total en Dolares | float64 | Numérica Contínua |\n",
        "| Provincia Sigla | object | Categórica Nominal |\n",
        "| Hora Visita | int64 | Categórica Nominal |"
      ],
      "metadata": {
        "id": "DhBTgO0upzBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importacion de Dataset**"
      ],
      "metadata": {
        "id": "cA4gBiRtbt_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDjHAyfpRktO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Instalación de Librerías\n",
        "!pip install dataprep\n",
        "\n",
        "#!pip install gapminder\n",
        "#!pip install mglearn\n",
        "#! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
        "#!pip install chart_studio\n",
        "\n",
        "# Importación de Librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import matplotlib.animation as animation\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "#import chart_studio.plotly as py\n",
        "\n",
        "\n",
        "import missingno as msno\n",
        "import scipy\n",
        "# La Librería Scipy es exclusiva de datos estadísticos\n",
        "\n",
        "import requests\n",
        "# La librería requests en Python es una herramienta poderosa y popular que se utiliza para realizar solicitudes HTTP de manera sencilla\n",
        "# y eficiente. Permite interactuar con páginas web, APIs RESTful, y otros servicios basados en HTTP\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# La librería warnings en Python se utiliza para gestionar y controlar mensajes de advertencia (warnings) durante la ejecución de un programa.\n",
        "# A diferencia de los errores, que detienen la ejecución del programa, los warnings son mensajes informativos que indican situaciones potencialmente\n",
        "# problemáticas, pero permiten que el programa continúe ejecutándose\n",
        "\n",
        "#import mglearn\n",
        "# La librería mglearn (abreviatura de mglearn) es una herramienta complementaria que facilita el aprendizaje y la enseñanza de Machine Learning en Python.\n",
        "# Está diseñada principalmente para ilustrar conceptos básicos de aprendizaje automático de manera visual e intuitiva\n",
        "\n",
        "#import graphviz\n",
        "# La librería graphviz en Python se utiliza para trabajar con Graphviz, una herramienta de visualización gráfica que permite crear y\n",
        "# representar grafos dirigidos y no dirigidos. Es especialmente útil para crear diagramas jerárquicos, flujos de trabajo, árboles de decisión,\n",
        "# redes de dependencias y otras estructuras gráficas\n",
        "\n",
        "import folium  #needed for interactive map\n",
        "from folium.plugins import HeatMap\n",
        "# La librería folium en Python se utiliza para crear mapas interactivos de manera sencilla y visualmente atractiva. Es una herramienta ideal para trabajar\n",
        "# con datos geoespaciales y visualizar información geográfica superpuesta en mapas\n",
        "\n",
        "#from ydata_profiling import ProfileReport\n",
        "from IPython.display import display\n",
        "#from IPython.display import HTML\n",
        "# La librería IPython.display de Python es un módulo utilizado principalmente en entornos interactivos como Jupyter Notebooks. Su función es proporcionar\n",
        "# herramientas para mostrar salidas de una manera más rica y flexible, como imágenes, gráficos, HTML, audio y más. Esto mejora la experiencia de visualización\n",
        "# y presentación de resultados\n",
        "# La librería display en Python es parte del paquete IPython.display, que proporciona funciones para mostrar objetos de manera interactiva y enriquecida\n",
        "# dentro de entornos como Jupyter Notebook o Google Colab.\n",
        "# Permite mostrar no solo texto, sino también imágenes, gráficos, HTML, Markdown, audio, video y otros tipos de datos de forma estructurada\n",
        "# y visualmente atractiva\n",
        "# La función HTML se usa para mostrar contenido HTML directamente en el cuaderno de Jupyter. Esto es especialmente útil para integrar código HTML en tus\n",
        "# celdas y ver cómo se presenta sin tener que crear archivos externos.\n",
        "\n",
        "from bokeh.io import show, output_file\n",
        "# La librería bokeh.io es parte del ecosistema de Bokeh en Python, una herramienta para crear visualizaciones interactivas de alta calidad que se pueden\n",
        "# integrar fácilmente en aplicaciones web o presentaciones.\n",
        "# Bokeh es especialmente útil cuando se quiere trabajar con gráficos dinámicos y visualizaciones interactivas para la web, como gráficos de líneas, barras,\n",
        "# dispersión, mapas, y más, todo en tiempo real.\n",
        "# Las funciones show y output_file provienen de la librería Bokeh, que se utiliza para crear visualizaciones interactivas en Python. Estas funciones son\n",
        "# clave para mostrar los gráficos creados con Bokeh, ya sea en un navegador web o como parte de un archivo HTML\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "# La librería bokeh.plotting de Bokeh en Python se utiliza para crear visualizaciones interactivas y dinámicas en el navegador web. Permite generar gráficos\n",
        "# y visualizaciones atractivas que los usuarios pueden explorar de manera interactiva, como hacer zoom, mover, o seleccionar puntos en los gráficos.\n",
        "# Bokeh es especialmente útil para proyectos que requieren visualización web o dashboard interactivo.\n",
        "# La función figure de la librería Bokeh en Python es el núcleo para crear gráficos interactivos y personalizados. Bokeh es una biblioteca poderosa para\n",
        "# la visualización de datos, y la función figure actúa como un lienzo donde puedes agregar elementos visuales, como gráficos de líneas, barras, puntos, etc.\n",
        "\n",
        "#from bokeh.models import DatetimeTickFormatter\n",
        "# bokeh.models contiene modelos que proporcionan herramientas, widgets y componentes que puedes utilizar para personalizar y mejorar las visualizaciones\n",
        "# en Bokeh.\n",
        "# Estos modelos permiten añadir interactividad, controlar las propiedades visuales de los elementos gráficos, y configurar la forma en que los gráficos\n",
        "# responden a las acciones del usuario.\n",
        "\n",
        "#from mlxtend.plotting import plot_decision_regions\n",
        "# La librería mlxtend.plotting es parte de mlxtend (machine learning extensions), una biblioteca de Python que proporciona herramientas adicionales para el\n",
        "# análisis y visualización de datos, especialmente orientadas a machine learning y análisis exploratorio. La sublibrería mlxtend.plotting está diseñada para\n",
        "# facilitar la visualización de resultados y modelos de aprendizaje automático, creando gráficos que son útiles tanto para la interpretación de modelos como\n",
        "# para la presentación de resultados\n",
        "\n",
        "#from dataprep.eda import create_report\n",
        "# La librería dataprep.eda es parte de la biblioteca dataprep en Python y está diseñada para facilitar el proceso de exploración y análisis de datos. Es una\n",
        "# herramienta muy útil para realizar un análisis exploratorio de datos (EDA) de manera rápida y eficiente, sin necesidad de escribir mucho código.\n",
        "# dataprep.eda automatiza muchas tareas comunes en la exploración de datos y te permite obtener información valiosa sobre tu conjunto de datos con poco esfuerzo\n",
        "\n",
        "#from gapminder import gapminder\n",
        "# Gapminder es una biblioteca utilizada para trabajar con el conjunto de datos Gapminder, que contiene información socioeconómica y de salud\n",
        "# de varios países a lo largo del tiempo. Este conjunto de datos es muy popular en análisis de datos, visualización y aprendizaje de estadísticas.\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder, PolynomialFeatures, MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score, HalvingRandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de Enlaces de los Datasets del Proyecto en Github\n",
        "URL1 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_1_Pedidos_61190.xlsx'\n",
        "URL2 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_2_Pedidos_61190.xlsx'\n",
        "URL3 = 'https://github.com/Leonardo-rodcas/Proyecto-DS-61190-E-Commerce/raw/refs/heads/main/2024_3_Pedidos_61190.xlsx'"
      ],
      "metadata": {
        "id": "VHPOcro3R9zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cremos Dataframes con los enlaces anteriores\n",
        "# A todos los campos los importo como String, para luego convertir particularmente los que no lo sean\n",
        "df_2024_Sem_1 = pd.read_excel(URL1, dtype='str')\n",
        "df_2024_Sem_2 = pd.read_excel(URL2, dtype='str')\n",
        "df_2024_Sem_3 = pd.read_excel(URL3, dtype='str')"
      ],
      "metadata": {
        "id": "Hs2xAAvLQPeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del primer dataframe sea String\n",
        "df_2024_Sem_1.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "acFtVQ__QS9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del segundo dataframe sea String\n",
        "df_2024_Sem_2.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O1hqBkhxQW_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos que todas las columnas del tercer dataframe sea String\n",
        "df_2024_Sem_3.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OFnA4-bfQZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos Dataframe Auxiliar con datos de Provicias\n",
        "URL3 = 'https://infra.datos.gob.ar/georef/provincias.json'\n",
        "response = requests.get(URL3)\n",
        "datos_json = json.loads(response.text)\n",
        "df_prov = pd.DataFrame.from_dict(datos_json['provincias'])\n",
        "\n",
        "# Renombramos la columna \"Id\" a \"Id Provincia\"\n",
        "df_prov = df_prov.rename(columns={'id': 'Id Provincia'})\n",
        "\n",
        "# Agregamos la columna \"Sigla Provincia\" y le aportamos un valor a cada una\n",
        "df_prov['Provincia Sigla']=\"\"\n",
        "df_prov.loc[df_prov['Id Provincia'] == '02', 'Provincia Sigla'] = 'CABA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '06', 'Provincia Sigla'] = 'BSAS'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '10', 'Provincia Sigla'] = 'CATA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '14', 'Provincia Sigla'] = 'CORD'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '18', 'Provincia Sigla'] = 'CTES'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '22', 'Provincia Sigla'] = 'CHAC'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '26', 'Provincia Sigla'] = 'CHUB'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '30', 'Provincia Sigla'] = 'ERIO'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '34', 'Provincia Sigla'] = 'FORM'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '38', 'Provincia Sigla'] = 'JUJU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '42', 'Provincia Sigla'] = 'PAMP'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '46', 'Provincia Sigla'] = 'RIOJ'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '50', 'Provincia Sigla'] = 'MEND'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '54', 'Provincia Sigla'] = 'MISI'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '58', 'Provincia Sigla'] = 'NEUQ'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '62', 'Provincia Sigla'] = 'RNEG'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '66', 'Provincia Sigla'] = 'SALT'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '70', 'Provincia Sigla'] = 'SJUA'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '74', 'Provincia Sigla'] = 'SLUI'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '78', 'Provincia Sigla'] = 'SCRU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '82', 'Provincia Sigla'] = 'SAFE'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '86', 'Provincia Sigla'] = 'SEST'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '90', 'Provincia Sigla'] = 'TUCU'\n",
        "df_prov.loc[df_prov['Id Provincia'] == '94', 'Provincia Sigla'] = 'TFUE'\n",
        "\n",
        "# Mostramos resultado\n",
        "df_prov.head(5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2T1fADC8QfuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Wrangling**"
      ],
      "metadata": {
        "id": "zxvqlJ2iZ8Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Concatenado de Dataframes**"
      ],
      "metadata": {
        "id": "2FLyOvICbW5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenamos los 3 Dataframes del año 2024\n",
        "frames = [df_2024_Sem_1, df_2024_Sem_2, df_2024_Sem_3]\n",
        "df_concat = pd.concat(frames)"
      ],
      "metadata": {
        "id": "SGLViFzsQe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Merge de Dataframes**"
      ],
      "metadata": {
        "id": "GNedlHmabmXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos Merge entre el Dataframe principal y el de provicias para agregar la columna Sigla de la provincia\n",
        "df = pd.merge(df_concat, df_prov, left_on = \"Id Provincia\", right_on = \"Id Provincia\", how = 'left')\n",
        "df.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3u7t2Ny5QksV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Registros en NaN**"
      ],
      "metadata": {
        "id": "LCjWcduLbtO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos registros NaN en los campos geográficos para que quede constancia de los mismos\n",
        "df_geo = df[['Entrega','Codigo Postal','Provincia','Provincia Sigla']]\n",
        "df_geo.loc[df_geo['Provincia Sigla'].isna()]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I46VaJYkQqpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos registros NaN en todo lo referente a los datos geográficos del Dataframe principal\n",
        "df = df.dropna(subset=['Provincia Sigla'])\n",
        "df.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4hK-DQi-QuSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos los casos que no tienen visitas\n",
        "df_sin_visita = df[['Entrega','Visita 1 Fecha','Estado Visita']]\n",
        "df_sin_visita.loc[df_sin_visita['Visita 1 Fecha'].isna()]"
      ],
      "metadata": {
        "id": "oyowlKUkivWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos registros NaN en todo lo referente a la Primer Visita\n",
        "df = df.dropna(subset=['Visita 1 Fecha'])\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jt8ENCWwjrT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cambio del tipo de datos de las columnas**"
      ],
      "metadata": {
        "id": "C5wvXc-fb2z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiamos el tipo de datos de las columnas que corresponda\n",
        "df = df.astype({\n",
        "    'Entrega': 'int64',\n",
        "    'Distribuidor': 'category',\n",
        "    'Distribuidor Sigla': 'category',\n",
        "    'Centro': 'category',\n",
        "    'Centro Sigla': 'category',\n",
        "    'Centro Tipo': 'category',\n",
        "    'Tipo de Distribución Comercial': 'category',\n",
        "    'Codigo Postal': 'int64',\n",
        "    'Id Provincia': 'int64',\n",
        "    'Provincia': 'category',\n",
        "    'Localidad': 'category',\n",
        "    'Departamento': 'category',\n",
        "    'Aglomerado': 'category',\n",
        "    'Id Zona Logistica': 'int64',\n",
        "    'Zona Logistica': 'category',\n",
        "    'Zona E-Commerce': 'category',\n",
        "    'Periodo': 'category',\n",
        "    'Año': 'int64',\n",
        "    'Mes Sigla': 'category',\n",
        "    'Mes Nombre': 'category',\n",
        "    'Mes Numero': 'int64',\n",
        "    'Trimestre Sigla': 'category',\n",
        "    'Trimestre Nombre': 'category',\n",
        "    'Trimestre Numero': 'int64',\n",
        "    'Semestre': 'int64',\n",
        "    'Año Semana': 'category',\n",
        "    'Dia Semana Sigla': 'category',\n",
        "    'Dia Semana Nombre': 'category',\n",
        "    'Dia Semana Numero': 'int64',\n",
        "    'Hora': 'int64',\n",
        "    'ID Visita 1 Motivo': 'category',\n",
        "    'Visita 1 Motivo': 'category',\n",
        "    'Dias Primer Visita': 'int64',\n",
        "    'Flag Visita 1 Puntual': 'category',\n",
        "    'Estado Visita': 'category',\n",
        "    'Estado Distribución': 'category',\n",
        "    'Calidad de la Direccion': 'category',\n",
        "    'Cantidad de Pedidos': 'int64',\n",
        "    'Visita 1 Puntual': 'int64',\n",
        "    'Cant. Primera Visita': 'int64',\n",
        "    'Cant. Vis. y Ent. 1ra Visita': 'int64',\n",
        "    'Cantidad Celulares': 'int64',\n",
        "    'Cantidad Tarjetas SIMs': 'int64',\n",
        "    'Cantidad Accesorios': 'int64',\n",
        "    'Cantidad Accesorios IOT': 'int64',\n",
        "    'Peso Bruto': 'float64',\n",
        "    'Costo Total de Materiales': 'float64',\n",
        "    'Valor Total USD': 'float64',\n",
        "})\n",
        "\n",
        "df['Fecha Pedido'] = pd.to_datetime(df['Fecha Pedido'])\n",
        "df['Visita 1 Fecha'] = pd.to_datetime(df['Visita 1 Fecha'])"
      ],
      "metadata": {
        "id": "61ld0MqYQzwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Renombramos las columnas**"
      ],
      "metadata": {
        "id": "BRYw6RTlb-9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiamos nombres de las columnas que necesiten ser más claras en lo descriptivo\n",
        "df = df.rename(columns={'Hora': 'Hora Pedido'})\n",
        "df = df.rename(columns={'Costo Total de Materiales': 'Valor Total en Pesos'})\n",
        "df = df.rename(columns={'Valor Total USD': 'Valor Total en Dolares'})\n",
        "df = df.rename(columns={'Semestre': 'Semestre Numero'})"
      ],
      "metadata": {
        "id": "0WDFaPB4Q3pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creación de nuevos campos**"
      ],
      "metadata": {
        "id": "zQ2a3vcdcG3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el campo \"Hora Visita\" en formato de 2 dígitos (los 2 de la izquierda del campo \"Visita 1 Hora\")\n",
        "df['Hora Visita'] = df['Visita 1 Hora'].str.slice(0, 2)\n",
        "\n",
        "# Cambiamos a Nan los valores Numeral (\"#\") del campo \"Hora Visita\"\n",
        "df.loc[df['Hora Visita'] == '#', 'Hora Visita'] = np.nan\n",
        "\n",
        "# Cambiamos el tipo de datos de esta nueva columna a \"Int64\"\n",
        "df['Hora Visita'] = df['Hora Visita'].astype('Int64')\n",
        "\n",
        "# Validamos que haya quedado correcto el cambio\n",
        "df[['Entrega','Hora Visita']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J7G6Ra02Q7Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el campo \"Tipo Material\"\n",
        "df['Tipo Material'] = np.nan  # Inicializamos la columna\n",
        "\n",
        "df.loc[(df['Cantidad Celulares'] > 0) & (df['Cantidad Accesorios'] == 0), 'Tipo Material'] = 'Celular'\n",
        "df.loc[(df['Cantidad Celulares'] == 0) & (df['Cantidad Accesorios'] > 0), 'Tipo Material'] = 'Accesorio'\n",
        "df.loc[(df['Cantidad Celulares'] > 0) & (df['Cantidad Accesorios'] > 0), 'Tipo Material'] = 'Celular + Accesorio'"
      ],
      "metadata": {
        "id": "sMobvrq8uJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Borrado de Campos innecesarios**"
      ],
      "metadata": {
        "id": "CD22LepYcMTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Borramos las columnas que no aportan valor al Dataframe\n",
        "df = df.drop(['Canal', 'Subcanal', 'Centro', 'Centro Sigla', 'Centro Tipo', 'Puesto de Expedicion', 'Visita 1 Trackeo', 'Visita 1 Transporte', 'Días contrato primera visita'], axis=1)\n",
        "df = df.drop(['Cantidad Tarjetas SIMs', 'Cantidad Accesorios IOT', 'nombre', 'nombre_completo', 'fuente', 'iso_id', 'iso_nombre'], axis=1)\n",
        "df = df.drop(['Latitud Provincia', 'Longitud Provincia', 'Latitud Departamento', 'Longitud Departamento', 'Latitud Localidad', 'Longitud Localidad'], axis=1)\n",
        "df = df.drop(['centroide', 'categoria', 'Año', 'Cantidad de Pedidos'], axis=1)"
      ],
      "metadata": {
        "id": "GwAc8v9aQ-n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición del Índice"
      ],
      "metadata": {
        "id": "Io7TwgLlZaov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indice del Dataframe Principal\n",
        "df = df.set_index('Entrega')"
      ],
      "metadata": {
        "id": "Q-oAzG3kZjxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos algunas estadísticas del Dataset\n",
        "df.describe().round().T"
      ],
      "metadata": {
        "id": "9wtv4kj7U8S8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Método describe()**\n",
        "En línea general se observan datos acordes sobre todo en los indicadores. Pero debemos revisar lo siguiente:\n",
        "* Días Primer Visita tiene:\n",
        "  * Un mínimo de -1. Estos casos no tienen visitas aún con lo cual se deberían quitar del análisis\n",
        "  * Casos que van entre 10 a 62 días para la primer visita. Se debería asignar la media a todos esos casos\n",
        "* Peso Bruto tiene un mínimo en 0 (cero), lo cual significa que existen algunos registros en cero\n",
        "* Peso Bruto tiene un peso máximo irreal. Debemos detectar y tratar esos registros\n",
        "* Valor Total en Pesos y Valor Total en Dolares tienen un mínimo en 0 (cero), lo cual significa que existen algunos registros en cero\n",
        "* El campo **\"Cant. Primera Visita\"** se puede borrar del Dataset ya que todos los registros estadísticos del mismo han quedado con valor 1 (uno) (media, minimo, maximo, Q1, Q2, Q3)\n",
        "\n",
        "Esto nos permite concluir que tenemos un muy buen dataset, con una alta calidad de datos"
      ],
      "metadata": {
        "id": "wjqdyul0SJRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Peso Bruto Mayor a 200 KG\n",
        "limite_peso_maximo = 200\n",
        "media_peso = df.loc[df['Peso Bruto'] < limite_peso_maximo, 'Peso Bruto'].mean()\n",
        "df.loc[df['Peso Bruto'] > limite_peso_maximo, 'Peso Bruto'] = media_peso"
      ],
      "metadata": {
        "id": "EeGlSaaoHGa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Peso Bruto = 0 (cero)\n",
        "df.loc[df['Peso Bruto'] == 0, 'Peso Bruto'] = media_peso"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bH-rGRUJauD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Valor Total en $ (Pesos Argentinos)\n",
        "media_pesos_ar = df.loc[df['Valor Total en Pesos'] > 0, 'Valor Total en Pesos'].mean()\n",
        "media_pesos_ar\n",
        "df.loc[df['Valor Total en Pesos'] == 0, 'Valor Total en Pesos'] = media_pesos_ar"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b9mM7uhrgGMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Valor Total en u$s (Dolares)\n",
        "media_dolares = df.loc[df['Valor Total en Dolares'] > 0, 'Valor Total en Dolares'].mean()\n",
        "df.loc[df['Valor Total en Dolares'] == 0, 'Valor Total en Dolares'] = media_dolares"
      ],
      "metadata": {
        "id": "Yo776f9YiFlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buscamos los pedidos con más de 10 días para su primer visita\n",
        "limite_dias_primer_visita_maximo = 11\n",
        "df.loc[df['Dias Primer Visita'] >= limite_dias_primer_visita_maximo, ['Dias Primer Visita']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4ZPQnqHroii3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamiento de Dias Primer Visita\n",
        "media_dias_primer_visita = df.loc[df['Dias Primer Visita'] < limite_dias_primer_visita_maximo, 'Dias Primer Visita'].mean()\n",
        "df.loc[df['Dias Primer Visita'] >= limite_dias_primer_visita_maximo, 'Dias Primer Visita'] = media_dias_primer_visita"
      ],
      "metadata": {
        "id": "1yXoqNHsh_We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrado del Campo \"Cant. Primera Visita\"\n",
        "df = df.drop(['Cant. Primera Visita'], axis=1)"
      ],
      "metadata": {
        "id": "oXlt9VrU3uMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Exploratorio de Datos (EDA)"
      ],
      "metadata": {
        "id": "Z-pMZkLcZUgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos meta información de la estructura del DataFrame\n",
        "df.shape"
      ],
      "metadata": {
        "id": "O9_bZeF9PfM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el Final del Dataset Principal\n",
        "df.tail(5)"
      ],
      "metadata": {
        "id": "I5fiNzVqPfM7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el Comienzo del Dataset Principal\n",
        "df.head(5)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tspoc3RiPfM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validamos las columnas, la cantidad de datos nulos y el tipo de formato de cada columna\n",
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NAQ4Ed59PfM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Antes de analizar los principales estadísticos, verificamos si nuestra estructura de datos es un dataframe\n",
        "type(df)"
      ],
      "metadata": {
        "id": "okHbhdsQPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación Estadisticas Preliminares\n",
        "df.describe().round(2).T\n",
        "\n",
        "# Se han corregido los datos tratados"
      ],
      "metadata": {
        "id": "iLVOpmlHPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contamos la cantidad de numeros 0 (ceros) por columnas\n",
        "nun_missing = (df == 0).sum()\n",
        "print(nun_missing)"
      ],
      "metadata": {
        "id": "O0iBim1BPfM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contamos la cantidad de Numerales (#) por columnas, ya que este caracter es el que utiliza el sistema de origen para representar los vaores en NULO\n",
        "nun_missing = (df == \"#\").sum()\n",
        "print(nun_missing)"
      ],
      "metadata": {
        "id": "oKm79hT7VzAY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos resumen de Vaores Nulos\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zYLaR92-J1KL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis Preliminar**\n",
        "* No existen valores duplicados ya que el origen de datos nos asegura que por su propia restricción de clave, que esa situación no va a ocurrir. Cabe aclarar que para este Dataset, en el sistema de origen, la clave/Id es el número de Entrega\n",
        "* El Numeral (#), en el sistema de origen de los datos, representa aquellos valores nulos. Por lo visto en este análisis preliminar, los únicos campos con datos nulos son \"Visita 1 Fecha\" y \"Hora Visita\". Es perfecto que eso así sea ya que son pedidos que aún no han sido visitados\n",
        "* Los valores de 0 (cero) en los campos del Dataset, son coherentes al 100% con el valor que representan\n",
        "* El siguiente Gráfico demuestra la gran calidad del dataset"
      ],
      "metadata": {
        "id": "th9lInoiXbW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficamos los nulos por columna\n",
        "msno.matrix(df, figsize = (20,5))"
      ],
      "metadata": {
        "id": "U51fRN3hqVp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Análisis con gráficas**"
      ],
      "metadata": {
        "id": "UkL7Ml7AYwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Barras de Cantidad de Pedidos por Zona E-Commerce\n",
        "df_zona_agrup = df.groupby('Zona E-Commerce', as_index=False).size()\n",
        "\n",
        "fig = px.bar(\n",
        "    df_zona_agrup,\n",
        "    x='Zona E-Commerce',\n",
        "    y='size',\n",
        "    title='Cantidad de Pedidos x Zona',\n",
        "    labels={'Zona E-Commerce': 'Zona', 'Cantidad de Pedidos': 'Cantidad de Pedidos'},\n",
        "    color='Zona E-Commerce',  # Colorear las barras en función del salario\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    color_discrete_map = {\n",
        "        'AMBA': '#7FD4C1',\n",
        "        'BALA': '#30BFDD',\n",
        "        'CUYO': '#8690FF',\n",
        "        'GBA': '#ACD0F4',\n",
        "        'LINO': '#F7C0BB',\n",
        "        'LISU': '#F8D0BB',\n",
        "        'MEDI': '#F9A0BB',\n",
        "        'NOA': '#D750BA',\n",
        "        'PATAGONIA': '#A2C0BB'\n",
        "\n",
        "        }\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_traces(\n",
        "    textposition='inside',  # Posición de los valores (texto) en las barras\n",
        "    marker_line_color= None,  # Color del borde de las barras\n",
        "    marker_line_width=1.5       # Grosor del borde de las barras\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    #xaxis_title='Categorías',\n",
        "    #yaxis_title='Ventas Totales',\n",
        "    #template='presentation',  # Tema del gráfico\n",
        "    bargap=0.0,  # Espacio entre las barras (0 a 1)\n",
        "    bargroupgap=0.1,  # Espacio entre grupos de barras\n",
        "    xaxis_title=\"Zonas\",\n",
        "    yaxis_title=\"Cantidad\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "98l9okOsZDKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porcentaje de Pedidos por Proveedor Logístico\n",
        "df_proveedor_agrup = df.groupby('Distribuidor Sigla', as_index=False).size()\n",
        "\n",
        "fig = px.pie(\n",
        "    df_proveedor_agrup,\n",
        "    names ='Distribuidor Sigla',\n",
        "    values ='size',\n",
        "    title='Cantidad de Pedidos x Proveedor',\n",
        "    labels={'Distribuidor Sigla': 'Dist', 'Cantidad de Pedidos': 'Cant'},\n",
        "    color='Distribuidor Sigla',  # Colorear las barras en función del salario\n",
        "    #text='Entrega',\n",
        "    width = 600,\n",
        "    height = 400,\n",
        "    color_discrete_map = {\n",
        "        'AND': '#7FD4C1',\n",
        "        'COA': '#30BFDD',\n",
        "        #'C': '#8690FF',\n",
        "        #'D': '#ACD0F4',\n",
        "        #'E': '#F7C0BB'\n",
        "        }\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_traces(\n",
        "    textposition='inside',  # Posición de los valores (texto) en las barras\n",
        "    marker_line_color= None,  # Color del borde de las barras\n",
        "    marker_line_width=1.5       # Grosor del borde de las barras\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    #xaxis_title='Categorías',\n",
        "    #yaxis_title='Ventas Totales',\n",
        "    #template='presentation',  # Tema del gráfico\n",
        "    bargap=0.0,  # Espacio entre las barras (0 a 1)\n",
        "    bargroupgap=0.1  # Espacio entre grupos de barras\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vh_n9Svnd1T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Efectividad de la Primer Visita por Proveedor y Periodo\n",
        "df_efect_prov_periodo_agrup = df.groupby(['Distribuidor Sigla','Periodo']).agg(\n",
        "    Cantidad_Pedidos = ('Fecha Pedido', 'count'),\n",
        "    Cantidad_Pedidos_Efectivos = ('Cant. Vis. y Ent. 1ra Visita', \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "df_efect_prov_periodo_agrup['Efectividad'] = df_efect_prov_periodo_agrup['Cantidad_Pedidos_Efectivos']/df_efect_prov_periodo_agrup['Cantidad_Pedidos']\n",
        "\n",
        "fig = px.line(\n",
        "    df_efect_prov_periodo_agrup,\n",
        "    x = \"Periodo\",\n",
        "    y = \"Efectividad\",\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    text = df_efect_prov_periodo_agrup[\"Efectividad\"].apply(lambda x: f\"{x:.1%}\"),\n",
        "    color='Distribuidor Sigla',\n",
        "    labels={'Efectividad': \"% Efectividad\", \"Periodo\": \"Mes\"}\n",
        "    )\n",
        "\n",
        "fig.update_traces(\n",
        "    mode=\"lines+markers+text\",\n",
        "    textposition=\"top center\"\n",
        "    )\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Efectividad de la Primer Visita por Proveedor y Zona\n",
        "df_efect_prov_zona_agrup = df.groupby(['Distribuidor Sigla','Zona E-Commerce']).agg(\n",
        "    Cantidad_Pedidos_2 = ('Fecha Pedido', 'count'),\n",
        "    Cantidad_Pedidos_Efectivos_2 = ('Cant. Vis. y Ent. 1ra Visita', \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "df_efect_prov_zona_agrup['Efectividad'] = df_efect_prov_zona_agrup['Cantidad_Pedidos_Efectivos_2']/df_efect_prov_zona_agrup['Cantidad_Pedidos_2']\n",
        "\n",
        "fig2 = px.line(\n",
        "    df_efect_prov_zona_agrup,\n",
        "    x = \"Zona E-Commerce\",\n",
        "    y = \"Efectividad\",\n",
        "    width = 800,\n",
        "    height = 400,\n",
        "    text = df_efect_prov_zona_agrup[\"Efectividad\"].apply(lambda x: f\"{x:.1%}\"),\n",
        "    color='Distribuidor Sigla',\n",
        "    labels={'Efectividad': \"% Efectividad\", \"Periodo\": \"Mes\"}\n",
        "    )\n",
        "\n",
        "fig2.update_traces(\n",
        "    mode=\"lines+markers+text\",\n",
        "    textposition=\"top center\"\n",
        "    )\n",
        "\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "JP73ILJvnljg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones EDA**\n",
        "Se comprueban ambas hipótesis planteadas al principio:\n",
        "* *Hipótesis 1:* La Zona Geográfica afecta a los indicadores de la Primer Visita. Por ejemplo:\n",
        "  * Se puede observar claramente la baja performance en AMBA de ambos proveedores\n",
        "  * También se observa como los dos proveedores mejoran sus números distribuyendo en la zona BALA (Buenos Aires - La Pampa)\n",
        "  * Llama también la atención que el proveedor de peor desempeño, tiene el mejor indicador de todos en la Zona GBA (Gran Buenos Aires)\n",
        "\n",
        "* *Hipótesis 2:* Los proveedores claramente tienen un desempeño distinto según las zonas\n",
        "  * Andreani tiene un comportamiento más estable/predecible a nivel nacional, incluso con el atenuante de tener un mayor volumen para distribuir\n",
        "  * Correo Argentino tiene números muchos más bajos, pero a favor de ellos se observa un crecimiento bastante sostenido a lo largo del año"
      ],
      "metadata": {
        "id": "xOhy39uh_b01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Estadístico de datos"
      ],
      "metadata": {
        "id": "tz0Q3mrnZqhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pedidos_mensuales =df.groupby(df['Fecha Pedido'].dt.to_period('M')).size()\n",
        "pedidos_mensuales.plot.line()"
      ],
      "metadata": {
        "id": "HWL8V3rzUKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis con scipy.stats\n",
        "Es un módulo de SciPy que proporciona herramientas estadísticas muy completas para análisis de datos. Estas funciones abarcan estadística descriptiva, distribución de probabilidad, pruebas de hipótesis, estadísticas no paramétricas, y mucho más"
      ],
      "metadata": {
        "id": "tKHqTOXq55TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe es un resumen estadístico (número de elementos, media, desviación estándar, etc.).\n",
        "scipy.stats.describe(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "MzTNJW2fOQLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desvío Estandar: El desvío estándar es una medida estadística que indica cuánto se desvían, en promedio, los valores de\n",
        "# un conjunto de datos respecto a su media. En otras palabras, muestra la dispersión o variabilidad de los datos. Es una de\n",
        "# las métricas más comunes para evaluar la dispersión de un conjunto de datos y se expresa en las mismas unidades que los\n",
        "# datos originales\n",
        "scipy.stats.tstd(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "s-g6tXc4DHTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media Geométrica: Calcula la media geométrica, útil cuando los datos representan tasas de cambio o proporciones\n",
        "scipy.stats.gmean(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "Tpj1Zwi5PeqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media Armónica: Calcula la media armónica, ideal para datos en los que las tasas o razones son relevantes.\n",
        "scipy.stats.hmean(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "ebnuNIV_PjeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Media recortada: sirve para calcular la media truncada (o media recortada) de un conjunto de datos. Es una medida\n",
        "# estadística que calcula la media de los datos después de eliminar un porcentaje determinado de valores extremos (tanto\n",
        "# los más bajos como los más altos) del conjunto. Esto es útil para reducir el efecto de valores atípicos o extremos sobre\n",
        "# el promedio\n",
        "scipy.stats.trim_mean(pedidos_mensuales,0.1)"
      ],
      "metadata": {
        "id": "HB46A1Z_P41n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moda de los datos: Encuentra el valor o valores que más se repiten en los datos\n",
        "scipy.stats.mode(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "t1u32K9nP6Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficiente de variacion: El coeficiente de variación (CV) es una medida de dispersión relativa que expresa la\n",
        "# desviación estándar como un porcentaje de la media. Se utiliza para comparar la variabilidad entre diferentes conjuntos\n",
        "# de datos, incluso si las magnitudes de las medias son muy diferentes.\n",
        "scipy.stats.variation(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "YELeNp1hOVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango intercuartílico: Calcula la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1), mostrando la\n",
        "# amplitud de los valores centrales del 50% de los datos\n",
        "scipy.stats.iqr(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "GUPNNItjOXKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculo del Error estandar de la media: Este valor cuantifica cuánto puede variar la media muestral con respecto a la\n",
        "# media verdadera de la población\n",
        "scipy.stats.sem(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "Xvy0_vqVZoEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficiente de asimetría: Mide la asimetría de una distribución de datos en torno a su media\n",
        "scipy.stats.skew(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "aigWj9BmOcxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Curtosis de los datos: Mide la \"apuntamiento\" de la distribución en comparación con una normal\n",
        "scipy.stats.kurtosis(pedidos_mensuales)"
      ],
      "metadata": {
        "id": "mwjQKEj_RBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A nivel estadísto, para este análisis específico de estadísticas, se ven datos razonables de:\n",
        "  * Mínimo\n",
        "  * Máximo\n",
        "  * Media\n",
        "  * Media Geométrica\n",
        "  * Media Armónica\n",
        "  * Media Recortada\n",
        "* La moda que aporta el metodo pierde valor ya que no hay repeticiones en el conjunto de datos\n",
        "* Se observa una muy alta varianza pero contrariamente, un bajo nivel del coeficiente de variación. El desvío estandar razonable con la unidad de cantidad de pedidos mensuales respecto a su media\n",
        "* Tambien la gráfica demuestra tener una asimetría positiva según SKEWNESS\n",
        "* Hay Exceso de Kurtosis ya que la misma es negativa"
      ],
      "metadata": {
        "id": "qvDBulz-P3oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análsis Univariado"
      ],
      "metadata": {
        "id": "hteUic0rZ1a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "pjsrarIJdeNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = [\n",
        "    'Fecha Pedido', 'Hora Pedido', 'Periodo',\n",
        "    'Mes Numero', 'Trimestre Numero', 'Dias Primer Visita',\n",
        "    'Peso Bruto', 'Valor Total en Pesos', 'Valor Total en Dolares',\n",
        "    ]\n",
        "columns = 3\n",
        "filas = len(variables)\n",
        "fig, axes = plt.subplots(len(variables) //columns, columns, figsize=(30,30))\n",
        "\n",
        "for current_idx, variable in enumerate(variables):\n",
        "    i = current_idx // columns\n",
        "    j = current_idx % columns\n",
        "    sns.histplot(df[variable], ax=axes[i][j], kde=True)\n",
        "    axes[i][j].set_title(variable)\n",
        "    axes[i][j].set_xlabel(\"\")\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "DTgXRyZkmigU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las mayoría de las distribuciones anteriores tienen variables categóricas, más alla de que sean números enteros (\"Fecha Pedido\", \"Mes Numero\", etc).\n",
        "\n",
        "Las que podemos utilizar y que sean representativas son \"Dias Primera Visita\", Peso Bruto\", \"Valor Total en Pesos\" y \"Valor Total en Dolares\""
      ],
      "metadata": {
        "id": "680wAoM4S3Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia Sigla',\n",
        "    y='Peso Bruto',\n",
        "    color = 'Provincia Sigla',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Peso Bruto por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "r3peGSn16QXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia Sigla',\n",
        "    y='Valor Total en Pesos',\n",
        "    color = 'Provincia Sigla',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Pesos por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aW1rrFXpBuPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 100)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 100)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Provincia Sigla',\n",
        "    y='Valor Total en Dolares',\n",
        "    color = 'Provincia Sigla',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Dolares por Provincia\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jYR9UvRzFrAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Peso Bruto',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Peso Bruto por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "9xm-8EsJH4io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Valor Total en Pesos',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Pesos por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aFkCgW87RKI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = df['Distribuidor'].unique()\n",
        "\n",
        "def color_aleatorio():\n",
        "    r = random.randint(0, 10)  # Bajo valor de rojo\n",
        "    g = random.randint(150, 255)  # Alto valor de verde\n",
        "    b = random.randint(0, 10)  # Bajo valor de azul\n",
        "    return f\"#{r:02x}{g:02x}{b:02x}\"  # Convertir a formato hexadecimal\n",
        "\n",
        "color_discrete_map = {categoria: color_aleatorio() for categoria in categorias}\n",
        "\n",
        "fig = px.box(\n",
        "    df,\n",
        "    x='Distribuidor',\n",
        "    y='Valor Total en Dolares',\n",
        "    color = 'Distribuidor',\n",
        "    color_discrete_map = color_discrete_map  # Asignar colores aleatorios\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Analisis Univariado Valor en Dolares por Distribuidor\",\n",
        "    width = 1200,\n",
        "    height = 600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "1JhRbFrsRp-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "De los boxplots analizados, vemos muchos outliers, y la conclusión es que esa situación se da porque hay distintos tipos de materiales. Para lograr gráficas con menos Outliers, se deberían separar:\n",
        "* Los pedidos que solo tienen **TELEFONOS**\n",
        "* Los pedidos que solo tienen **ACCESORIOS**\n",
        "* Los pedidos que tienen **TELEFONOS** y **ACCESORIOS** a la vez"
      ],
      "metadata": {
        "id": "D--utYKeUDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análsis Bivariado"
      ],
      "metadata": {
        "id": "hGeHgKcIZ7zK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "3KMA-FRWd2tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "px.scatter(\n",
        "    df,\n",
        "    x='Valor Total en Dolares',\n",
        "    y='Valor Total en Pesos',\n",
        "    color='Distribuidor',\n",
        "    size='Peso Bruto',\n",
        "    hover_data=['Valor Total en Pesos']\n",
        ")"
      ],
      "metadata": {
        "id": "WEvisbDgY-s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_spearman = df.corr(method=\"spearman\")\n",
        "corr_spearman"
      ],
      "metadata": {
        "id": "VjX6-kcDA4rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "\n",
        "sns.heatmap(\n",
        "    df.corr(method='spearman'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")\n"
      ],
      "metadata": {
        "id": "-UqgAb1qV8CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_pearson = df.corr(method=\"pearson\")\n",
        "corr_pearson"
      ],
      "metadata": {
        "id": "0RdI9b6OHNX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "sns.heatmap(\n",
        "    df.corr(method='pearson'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")"
      ],
      "metadata": {
        "id": "Fg_6KgpINXmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_kendall = df.corr(method=\"kendall\")\n",
        "corr_kendall"
      ],
      "metadata": {
        "id": "hwF31QWuHnuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.xticks(rotation = 90)\n",
        "plt.yticks(rotation = 0)\n",
        "\n",
        "sns.heatmap(\n",
        "    df.corr(method='kendall'),\n",
        "    cbar = True,\n",
        "    square = True,\n",
        "    annot=True,\n",
        "    fmt= '.2f',\n",
        "    annot_kws={'size': 6},\n",
        "    cmap= 'coolwarm'\n",
        ")"
      ],
      "metadata": {
        "id": "uKprn0WEWpA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "* Se observa alta correlación entre las distintas clasificaciones de fecha (**\"Mes Numero\"**, **\"Trimestre Número\"** y **\"Semestre\"**).\n",
        "* Se observa también una muy fuerte correlación entre el valor de cada **\"Entrega\"** en **Pesos Argentinos** y **Dólares**. Esto si se puede ver como algo causal, ya que a mayor cantidad de pesos, siempre vamos a poder convertir una mayor cantidad de Dólares\n",
        "* Se observa una correlación intermedia o moderada entre el **\"Cantidad de Celulares\"** de las **\"Entregas\"** y el **\"Peso Bruto\"**, **\"Valor Total en Pesos\"** y **\"Valor Total en Dolares\"** que hay en cada una de ellas\n",
        "* Las correlaciones más débiles se da entre **\"Días Primera Visita\"** y **\"Puntualidad Primera Visita\"**. Eso es totalmente lógico, porque mientras más días se tarda en visitar un cliente, menos probabilidad existe de que la puntualidad se cumpla\n",
        "* También existe una correlación muy débil entre la **\"Cantidad de Celulares\"** y la **\"Cantidad de Accesorios\"**\n"
      ],
      "metadata": {
        "id": "13YUHv9gcZDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis Multivariado"
      ],
      "metadata": {
        "id": "8dvaha2faAUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis con Gráficas"
      ],
      "metadata": {
        "id": "ntmOfduRv5Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=120)\n",
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HKchv9fPv1BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "No se observan grandes correlaciones excepto en las variables **\"Valor Total en Pesos\"** y **\"Valor Total en Dolares\"**.\n",
        "\n",
        "La mayoría del resto de las gráficas muestran una gran dispersión. En algunas se observan claramente ciertos outliers que se analizará su tratamiento."
      ],
      "metadata": {
        "id": "atgL8MpL_pEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingeniería de atributos"
      ],
      "metadata": {
        "id": "oah9GldXaaiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoder\n",
        "Utilizamos One Hot Encoder para los campos cuya variable categórica tiene hasta 4 valores posible"
      ],
      "metadata": {
        "id": "27klMKnHrL7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el codificador OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)  # sparse=False para devolver una matriz densa\n",
        "\n",
        "# Seleccionar las columnas a transformar\n",
        "columns_to_encode = ['Distribuidor', 'Tipo de Distribución Comercial', 'Zona E-Commerce', 'Estado Visita', 'Estado Distribución', 'Tipo Material']\n",
        "\n",
        "# Ajustar y transformar las columnas categóricas\n",
        "encoded_data = one_hot_encoder.fit_transform(df[columns_to_encode])\n",
        "\n",
        "# Crear un DataFrame con los resultados de One Hot Encoding\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=one_hot_encoder.get_feature_names_out(columns_to_encode))\n",
        "\n",
        "# Nos aseguramos que ambos Dataframe tengan el mismo Indice\n",
        "encoded_df.index = df.index\n",
        "\n",
        "# Unir el DataFrame original con las columnas codificadas\n",
        "df_encoded = pd.concat([df, encoded_df], axis=1).drop(columns=columns_to_encode)"
      ],
      "metadata": {
        "id": "meapmAaga8mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoder\n",
        "Utilizamos Label Encoder para las variables categóricas que tienen más de 4 clasificaciones"
      ],
      "metadata": {
        "id": "PCRll6Eo4Lnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un diccionario para almacenar los LabelEncoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Aplicamos LabelEncoder a cada columna de interés\n",
        "for column in ['Localidad', 'Departamento', 'Aglomerado', 'ID Visita 1 Motivo']:\n",
        "    le = LabelEncoder()  # Creamos un LabelEncoder para cada columna\n",
        "    df_encoded[column] = le.fit_transform(df_encoded[column])  # Transformamos la columna\n",
        "    label_encoders[column] = le  # Guardamos el LabelEncoder para uso futuro"
      ],
      "metadata": {
        "id": "5FS1Nd5qrqPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ordinal Encoding\n",
        "Utilizamos Ordinal Encoding porque tenemos un campo que tiene logica ordinal. A priori, el orden debe ser alfabético descendiente\n"
      ],
      "metadata": {
        "id": "AgEiWdNv-Gp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el orden de las categorías\n",
        "orden_calidad = [['#', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A']]\n",
        "\n",
        "# Crear y aplicar el OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder(categories=orden_calidad)\n",
        "df_encoded['Calidad de la Direccion Codificada'] = ordinal_encoder.fit_transform(df_encoded[['Calidad de la Direccion']])"
      ],
      "metadata": {
        "id": "l6bZlrl4-mM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento y Testeo\n",
        "Nuestro Dataset cuenta con la variable a predecir la cual es \"Cant. Vis. y Ent. 1ra Visita\". Esta variable solo tiene como valores 0 y 1. Detalles:\n",
        "* 0 = No Entregada\n",
        "* 1 = Entregada"
      ],
      "metadata": {
        "id": "NYewbqv_anWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos Lista de columnas para seleccionar las que van a ser evaluadas en el modelo\n",
        "df_encoded.columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Lu8zxbT2P8_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos X\n",
        "X = df_encoded[['Codigo Postal', 'Id Provincia', 'Localidad', 'Departamento', 'Aglomerado', 'Mes Numero',\n",
        "       'Dia Semana Numero', 'Hora Pedido', 'Cantidad Celulares', 'Cantidad Accesorios', 'Peso Bruto',\n",
        "       'Valor Total en Dolares', 'Distribuidor_Correo Andreani', 'Distribuidor_Correo Argentino',\n",
        "       'Tipo de Distribución Comercial_Pedido Combinado', 'Tipo de Distribución Comercial_Pedido Multiple',\n",
        "       'Tipo de Distribución Comercial_Pedido Simple', 'Zona E-Commerce_#', 'Zona E-Commerce_AMBA',\n",
        "       'Zona E-Commerce_BALA', 'Zona E-Commerce_CUYO', 'Zona E-Commerce_GBA', 'Zona E-Commerce_LINO',\n",
        "       'Zona E-Commerce_LISU', 'Zona E-Commerce_MEDI', 'Zona E-Commerce_NOA', 'Zona E-Commerce_PATAGONIA',\n",
        "       'Tipo Material_Accesorio', 'Tipo Material_Celular', 'Tipo Material_Celular + Accesorio', 'Calidad de la Direccion Codificada']]\n",
        "X.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YqSU3R8nFjqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos y\n",
        "y = df_encoded['Cant. Vis. y Ent. 1ra Visita'].values\n",
        "y"
      ],
      "metadata": {
        "id": "d0-d482lGk2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "UJsrEI-KseCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbol de decisión"
      ],
      "metadata": {
        "id": "UeLA4NjhZVD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple"
      ],
      "metadata": {
        "id": "Obbr3gUZxWxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_tree = DecisionTreeClassifier(max_depth= 5)"
      ],
      "metadata": {
        "id": "-CHzyVWxpUM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# 1 Segundo de ejecución\n",
        "clf_tree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FOfy-1vHqo28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafico del Arbol de Decisión\n",
        "fig = plt.figure(figsize=(12,10))\n",
        "plot_tree(clf_tree,\n",
        "          feature_names = X.columns,\n",
        "          filled = True,\n",
        "          rounded = True,\n",
        "          precision = 3,\n",
        "          class_names = True\n",
        "          )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n6rHRxN0tL7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 1 segundo de ejecución\n",
        "y_pred_tree = clf_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "tINEUGvL3Bdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_tree = confusion_matrix(y_test,y_pred_tree)\n",
        "print(cm_tree)\n",
        "disp_tree = ConfusionMatrixDisplay(confusion_matrix=cm_tree, display_labels=clf_tree.classes_)\n",
        "disp_tree.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1dR3u17DpTG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Arbol de Decisión (Validación Simple)\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"Precisión del modelo Arbol de Decisión Validación Simple: {accuracy_tree:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_tree = classification_report(y_test, y_pred_tree)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_tree)"
      ],
      "metadata": {
        "id": "ayhMFCCAv8EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple con Hiperparámetros"
      ],
      "metadata": {
        "id": "aU1BCZ_TxmO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la instancia con los hiperparámetros propuestos por Halving Randomized Search\n",
        "clf_tree_hp = DecisionTreeClassifier(\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf = 1,\n",
        "    max_depth= 3,\n",
        "    criterion = 'gini'\n",
        ")"
      ],
      "metadata": {
        "id": "ZjY-RXMCxPUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con Hiperparámetros\n",
        "# Menos de 1 segundo con hiperparámetros\n",
        "clf_tree_hp.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "c5Wwgqo7xkZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos la predicción con Hiperparámetros\n",
        "# Menos de un segundo de ejecución con hiperparámetros\n",
        "y_pred_tree_hp = clf_tree_hp.predict(X_test)"
      ],
      "metadata": {
        "id": "1bETklGSzAqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica con Hiperparametros\n",
        "cm_tree_hp = confusion_matrix(y_test,y_pred_tree_hp)\n",
        "print(cm_tree_hp)\n",
        "disp_tree_hp = ConfusionMatrixDisplay(confusion_matrix=cm_tree_hp, display_labels=clf_tree_hp.classes_)\n",
        "disp_tree_hp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5uYj8LPxzdQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Arbol de Decisión (Validación Simple con Hiperparámetros)\n",
        "accuracy_tree_hp = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"Precisión del modelo Arbol de Decisión Validación Simple con Hiperparámetros: {accuracy_tree_hp:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_tree_hp = classification_report(y_test, y_pred_tree)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_tree_hp)"
      ],
      "metadata": {
        "id": "ynBNrQtvpg1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observaciones Finales del Arbol de Decisión**\n",
        "\n",
        "Se realizaron distintas pruebas y el accuracy daba 100%. Y leyendo como se ha resuelto el árbol de decisión, concluimos que se deben retirar las siguientes variables:\n",
        "* La variable **\"Estado Distribución\"** y **\"Estado Visita\"** muy probablemente se deben retirar del análisis y eso sería lógico, porque al momento que se realice la predicción, el estado de la entrega siempre va a ser **\"No Entregada\"**\n",
        "* La variable **\"Dias Primera Visita\"**. Al principio del análisis el valor de la misma siempre va a ser 0 (cero)\n",
        "* La variable **\"Id Visita 1 Motivo\"** al principio, siempre va a ser un valor nulo\n",
        "* La variable **\"Visita 1 Puntual\"** al principio, siempre va a ser un 0 (cero = no puntual)\n",
        "* La validación simple sin Hiperparámetros es más real que la validación simple con Hiperparámetros. Esta última, siempre predice 1 (que el pedido se entregó). Esto nos un da un indicio de que muy probablemente las variables seleccionadas estén desbalanceadas o que estén faltando variables de interés al modelo"
      ],
      "metadata": {
        "id": "4QK_40-p4Rvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ramdom Forest"
      ],
      "metadata": {
        "id": "LuOhBppy8zV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple"
      ],
      "metadata": {
        "id": "R2nC_08E1Glr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_forest = RandomForestClassifier(random_state=42, n_estimators=65)"
      ],
      "metadata": {
        "id": "9jpQOOWtTDr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# 24 segundos de ejecución\n",
        "clf_forest.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7hoDAsfr3k8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 2 segundos de ejecución\n",
        "y_pred_forest = clf_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "J3aDqRofT2qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_forest = confusion_matrix(y_test,y_pred_forest)\n",
        "print(cm_forest)\n",
        "disp_forest = ConfusionMatrixDisplay(confusion_matrix=cm_forest, display_labels=clf_forest.classes_)\n",
        "disp_forest.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZeGYw1_BrKzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Random Forest (Validación Simple)\n",
        "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
        "print(f\"Precisión del modelo Random Forest (Validación Simple): {accuracy_forest:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_forest = classification_report(y_test, y_pred_forest)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_forest)"
      ],
      "metadata": {
        "id": "mdsdm3L8vYmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple con Hiperparámetros"
      ],
      "metadata": {
        "id": "18foRhmp1NPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la instancia con los hiperparámetros propuestos por Halving Randomized Search\n",
        "clf_forest_hp = RandomForestClassifier(\n",
        "    n_estimators = 100,\n",
        "    min_samples_split = 5,\n",
        "    min_samples_leaf = 2,\n",
        "    max_features = 'log2',\n",
        "    max_depth = 3,\n",
        "    bootstrap = True,\n",
        "    random_state = 42\n",
        ")"
      ],
      "metadata": {
        "id": "UPf1qC7r1lVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento Random Forest con Hiperparámetros\n",
        "# 6 segundos de ejecución con hiperparámetros\n",
        "clf_forest_hp.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lEF23VLx1zcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción del Modelo con Hiperparámetros\n",
        "# Menos de un segundo de ejecución con Hiperparámetros\n",
        "y_pred_forest_hp = clf_forest.predict(X_test)"
      ],
      "metadata": {
        "id": "HBxwnaZa2UOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_forest_hp = confusion_matrix(y_test,y_pred_forest_hp)\n",
        "print(cm_forest_hp)\n",
        "disp_forest_hp = ConfusionMatrixDisplay(confusion_matrix=cm_forest_hp, display_labels=clf_forest_hp.classes_)\n",
        "disp_forest_hp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n-jfm03N3t1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Random Forest (Validación Simple con Hiperparámetros)\n",
        "accuracy_forest_hp = accuracy_score(y_test, y_pred_forest)\n",
        "print(f\"Precisión del modelo Random Forest (Validación Simple con Hiperparámetros): {accuracy_forest_hp:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_forest_hp = classification_report(y_test, y_pred_forest)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_forest_hp)"
      ],
      "metadata": {
        "id": "MVyL0iszrRut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observaciones Finales Random Forest**\n",
        "* Ambas matrices de confusión han arrojado exactamente el mismo resultado con y sin hiperparámetros\n",
        "* Este modelo es mucho más real que el **Arbol de Decisión** (con y sin hiperparámetros), ya que los datos se ajustan mucho más a la realidad actual del proceso que se está analizando\n",
        "* A pesar de ser mejor, los niveles de predicción no llevan a nuestro proceso a otro nivel de servicio\n"
      ],
      "metadata": {
        "id": "paVfZy0R4zTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "RSheDtHCVnqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple"
      ],
      "metadata": {
        "id": "xtenKGTFdgxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "scaler_knn = StandardScaler()\n",
        "X_train_scaled_knn = scaler_knn.fit_transform(X_train)\n",
        "X_test_scaled_knn = scaler_knn.transform(X_test)"
      ],
      "metadata": {
        "id": "pJF_aRviWkN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=9)"
      ],
      "metadata": {
        "id": "FK-piAVS2JaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# Menos de 1 segundo de ejecución\n",
        "clf_knn.fit(X_train_scaled_knn, y_train)"
      ],
      "metadata": {
        "id": "IVOZbY5p2QH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 1 minuto y 11 segundos de ejecución\n",
        "y_pred_knn = clf_knn.predict(X_test_scaled_knn)"
      ],
      "metadata": {
        "id": "ZQMsh8xk2U1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_knn = confusion_matrix(y_test,y_pred_knn)\n",
        "print(cm_knn)\n",
        "disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn, display_labels=clf_knn.classes_)\n",
        "disp_knn.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hVtJsESruTFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión KNN (Validación Simple)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"Precisión del modelo KNN (Validación Simple): {accuracy_knn:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_knn = classification_report(y_test, y_pred_knn)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_knn)"
      ],
      "metadata": {
        "id": "-pRzuPoT2ZuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple con Hiperparámetros"
      ],
      "metadata": {
        "id": "udKiTguldvcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la instancia con los hiperparámetros propuestos por Halving Randomized Search\n",
        "clf_knn_hp = KNeighborsClassifier(\n",
        "    weights = 'uniform',\n",
        "    n_neighbors = 10,\n",
        "    metric = 'euclidean'\n",
        ")"
      ],
      "metadata": {
        "id": "MOKF2GRXd3kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# Menos de 1 segundo de ejecución con hiperparámetros\n",
        "clf_knn_hp.fit(X_train_scaled_knn, y_train)"
      ],
      "metadata": {
        "id": "BmzvWWvqe2zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 1 minuto y 6 segundos con hiperparámetros\n",
        "y_pred_knn_hp = clf_knn_hp.predict(X_test_scaled_knn)"
      ],
      "metadata": {
        "id": "kDYuTPMyfA67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_knn_hp = confusion_matrix(y_test,y_pred_knn_hp)\n",
        "print(cm_knn_hp)\n",
        "disp_knn_hp = ConfusionMatrixDisplay(confusion_matrix=cm_knn_hp, display_labels=clf_knn_hp.classes_)\n",
        "disp_knn_hp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oH_SL1nBiI3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión KNN (Validación Simple con Hiperparámetros)\n",
        "accuracy_knn_hp = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"Precisión del modelo KNN (Validación Simple con Hiperparámetros): {accuracy_knn_hp:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_knn_hp = classification_report(y_test, y_pred_knn)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_knn_hp)"
      ],
      "metadata": {
        "id": "QsBoaU_Gixqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observaciones Finales KNN\n",
        "* La validación simple ha funcionado mejor que la validación con Hiperparámetros\n",
        "* Los resultados son muy similares a Random Forest\n",
        "* Los niveles de acierto tampoco llevan a nuestro proceso a un nivel superior"
      ],
      "metadata": {
        "id": "QAYGrtmujOTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística\n"
      ],
      "metadata": {
        "id": "qE5lPoSqFl2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple"
      ],
      "metadata": {
        "id": "odWYeml-kjVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalar los datos\n",
        "scaler_reg_log = StandardScaler()\n",
        "X_train_scaled_reg_log = scaler_reg_log.fit_transform(X_train)\n",
        "X_test_scaled_reg_log = scaler_reg_log.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "-Aet4x_SDEbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia del modelo\n",
        "clf_reg_log=LogisticRegression(solver='lbfgs', random_state=42, max_iter = 1000)"
      ],
      "metadata": {
        "id": "bwwv2Mr3S1Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# 1 segundo de Ejecución\n",
        "clf_reg_log.fit(X_train_scaled_reg_log, y_train)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nCrOoSSyS9M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 1 segundo de Ejecución\n",
        "y_pred_reg_log = clf_reg_log.predict(X_test_scaled_reg_log)"
      ],
      "metadata": {
        "id": "MuteWwfNXn7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_reg_log = confusion_matrix(y_test,y_pred_reg_log)\n",
        "print(cm_reg_log)\n",
        "disp_reg_log = ConfusionMatrixDisplay(confusion_matrix=cm_reg_log, display_labels=clf_reg_log.classes_)\n",
        "disp_reg_log.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bTDMkodDxKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Regresión Logística (Validación Simple)\n",
        "accuracy_reg_log = accuracy_score(y_test, y_pred_reg_log)\n",
        "print(f\"Precisión del modelo de Regresión Logística (Validación Simple): {accuracy_reg_log:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_reg_log = classification_report(y_test, y_pred_reg_log)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_reg_log)"
      ],
      "metadata": {
        "id": "e_vuLvb-w9uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación Simple con Hiperparámetros"
      ],
      "metadata": {
        "id": "T5vRibRkk_V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de la instancia con los hiperparámetros propuestos por Halving Randomized Search\n",
        "clf_reg_log_hp = LogisticRegression(\n",
        "    solver='saga',\n",
        "    penalty='l2',\n",
        "    C=0.01,\n",
        "    random_state=42,\n",
        "    max_iter=1000  # Incrementamos max_iter por estabilidad\n",
        ")"
      ],
      "metadata": {
        "id": "nwFlGls8lEN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos y la etiqueta\n",
        "# 1 segundo de Ejecución\n",
        "clf_reg_log_hp.fit(X_train_scaled_reg_log, y_train)"
      ],
      "metadata": {
        "id": "Tc6LHHq4mIt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se realiza la predicción con el modelo entrenado\n",
        "# 1 segundo de Ejecución\n",
        "y_pred_reg_log_hp = clf_reg_log_hp.predict(X_test_scaled_reg_log)"
      ],
      "metadata": {
        "id": "eEzR4Lbxmg0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_reg_log_hp = confusion_matrix(y_test,y_pred_reg_log_hp)\n",
        "print(cm_reg_log_hp)\n",
        "disp_reg_log_hp = ConfusionMatrixDisplay(confusion_matrix=cm_reg_log_hp, display_labels=clf_reg_log_hp.classes_)\n",
        "disp_reg_log_hp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S_DlI1RzmsaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión Regresión Logística (Validación Simple con Hiperparámetros)\n",
        "accuracy_reg_log_hp = accuracy_score(y_test, y_pred_reg_log)\n",
        "print(f\"Precisión del modelo de Regresión Logística (Validación Simple con Hiperparámetros): {accuracy_reg_log_hp:.6f}\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "class_report_reg_log_hp = classification_report(y_test, y_pred_reg_log)\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(class_report_reg_log_hp)"
      ],
      "metadata": {
        "id": "7-rbza1em7Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observaciones Finales de Regresión Logística\n",
        "Definitivamente, es el método que peor ha funcionado, a pesar de tener un Accuracy similar al resto de los modelos. Este Accuracy, es para desconfiar ya que el modelo, siempre predice 1 (uno). Nunca predice 0 (cero)."
      ],
      "metadata": {
        "id": "0mMorz_OyPfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación del Modelo"
      ],
      "metadata": {
        "id": "zSoeO4nDawAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metricas Generales"
      ],
      "metadata": {
        "id": "3E-ndd7p0bTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones Generales Validacióm Simple (con y sin Hiperparámetros)\n",
        "Los 4 modelos han tenido resultados muy parecidos. Si bien es cierto, Random Forest ha podido representar mejor la situación actual, ninguno de los métodos logra llevar las predicciones a un nivel que haga un diferencial en el proceso respecto de lo que tenemos actualmente.\n",
        "\n",
        "El nivel de análisis actual para estos modelos, determina que aún debemos seguir indagando en la naturaleza de los datos. Sin dudas, nuestros datos están desbalanceados y debemos avanzar en técnicas que nos permitan llegar a la meta propuesta"
      ],
      "metadata": {
        "id": "vzLgtMExv37a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metricas = {\n",
        "    \"Metrica\": [\"Accuracy\", \"Precision\", \"Sensibilidad\", \"Especificidad\", \"F1 Score\"],\n",
        "    \"Arbol de Decisión\": [\"0,814297\", \"0,815794\", \"0,997632\",\"0,002287\", \"0,897596\"],\n",
        "    \"Random Forest\": [\"0,793542\", \"0,815717\", \"0,964916\", \"0,034509\", \"0,884066\"],\n",
        "    \"KNN\": [\"0,797124\", \"0,815700\", \"0,970620\", \"0,0286939\", \"0,886442\"],\n",
        "    \"Regresión Logística\": [\"0,815807\", \"0,815806\", \"1,000000\", \"0,000000\", \"0.898561\"],\n",
        "    \"Obsercaciones\": [\"Exactitud\", \"Tasa Predictiva Positiva\", \"Tasa de Verdaderos Positivos\", \"Tasa de Verdaderos Negativos\", \"\"]\n",
        "}\n",
        "df_metricas = pd.DataFrame(metricas)\n",
        "\n",
        "# Mostrar tabla con estilo en Colab\n",
        "df_metricas.style.set_properties(**{'font-size': '15px', 'text-align': 'right'})"
      ],
      "metadata": {
        "id": "2uRZWhat6xum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización del Modelo\n",
        "Utilizaremos Stratified K Fold"
      ],
      "metadata": {
        "id": "VbM0mBO2bDSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos la instancia StratifiedKFold\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "DUw9Pht8aeQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbol de Decisión"
      ],
      "metadata": {
        "id": "4aL3XPzpog4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un nuevo modelo de Arbol de Decisión. No es recomendable usar un modelo ya entrenado\n",
        "#clf_tree_skf = DecisionTreeClassifier(random_state=42, max_depth= 5)\n",
        "\n",
        "clf_tree_skf_hp = DecisionTreeClassifier(\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf = 1,\n",
        "    max_depth= 3,\n",
        "    criterion = 'gini'\n",
        ")"
      ],
      "metadata": {
        "id": "yWpLYd4jppA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista para guardar mediciones\n",
        "accuracies_tree_skf_hp = []"
      ],
      "metadata": {
        "id": "GEBKIQ8opyXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo for de Stratified K Fold para el Arbol de Decisión\n",
        "# 4 segundos de ejecución\n",
        "# Accuracy Promedio 0.814443 vs 0.814209 de la Validación Simple vs 0.814384 con Hiperparámetros\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Dividimos los datos de entrenamiento y prueba\n",
        "    X_train_tree_skf_hp, X_test_tree_skf_hp = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_tree_skf_hp, y_test_tree_skf_hp = y[train_index], y[test_index]\n",
        "\n",
        "    # Entrenamos el nuevo modelo\n",
        "    clf_tree_skf_hp.fit(X_train_tree_skf_hp, y_train_tree_skf_hp)\n",
        "\n",
        "    # Predecir los resultados en el conjunto de prueba\n",
        "    y_pred_tree_skf_hp = clf_tree_skf_hp.predict(X_test_tree_skf_hp)\n",
        "\n",
        "    # Calculamos la precisión\n",
        "    acc_tree_skf_hp = accuracy_score(y_test_tree_skf_hp, y_pred_tree_skf_hp)\n",
        "    accuracies_tree_skf_hp.append(acc_tree_skf_hp)\n",
        "    print(f\"Fold {fold}: Accuracy = {acc_tree_skf_hp:.6f}\")\n",
        "\n",
        "    # Creamos la Matriz de Confusión Gráfica\n",
        "    cm_tree_skf_hp = confusion_matrix(y_test_tree_skf_hp,y_pred_tree_skf_hp)\n",
        "    print(cm_tree_skf_hp)\n",
        "    disp_tree_skf_hp = ConfusionMatrixDisplay(confusion_matrix=cm_tree_skf_hp, display_labels=clf_tree_skf_hp.classes_)\n",
        "    disp_tree_skf_hp.plot()\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Resultados finales\n",
        "print(f\"Arbol de Decisión - Media de Accuracy: {sum(accuracies_tree_skf_hp) / len(accuracies_tree_skf_hp):.6f}\")"
      ],
      "metadata": {
        "id": "5YVrmwdRqb4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "430AHvaHaiiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un nuevo modelo Random Forest. No es recomendable usar un modelo ya entrenado\n",
        "clf_forest_skf_hp = RandomForestClassifier(random_state=42, n_estimators=65)"
      ],
      "metadata": {
        "id": "O7y5no2odETs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista para guardar mediciones\n",
        "accuracies_forest_skf_hp = []"
      ],
      "metadata": {
        "id": "Vx1RXG0edhik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo for de Stratified K Fold para Random Forest\n",
        "# 2 miutos con 18 segundos de ejecución\n",
        "# Accuracy Promedio 0.804919 vs 0.805148 de la Validación Simple vs 0.814384 con hiperparámetros\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Dividimos los datos de entrenamiento y prueba\n",
        "    X_train_forest_skf_hp, X_test_forest_skf_hp = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_forest_skf_hp, y_test_forest_skf_hp = y[train_index], y[test_index]\n",
        "\n",
        "    # Entrenamos el nuevo modelo\n",
        "    clf_forest_skf_hp.fit(X_train_forest_skf_hp, y_train_forest_skf_hp)\n",
        "\n",
        "    # Predecir los resultados en el conjunto de prueba\n",
        "    y_pred_forest_skf_hp = clf_forest_skf_hp.predict(X_test_forest_skf_hp)\n",
        "\n",
        "    # Calculamos la precisión\n",
        "    acc_forest_skf_hp = accuracy_score(y_test_forest_skf_hp, y_pred_forest_skf_hp)\n",
        "    accuracies_forest_skf_hp.append(acc_forest_skf_hp)\n",
        "    print(f\"Fold {fold}: Accuracy = {acc_forest_skf_hp:.6f}\")\n",
        "\n",
        "    # Creamos la Matriz de Confusión Gráfica\n",
        "    cm_forest_skf_hp = confusion_matrix(y_test_forest_skf_hp,y_pred_forest_skf_hp)\n",
        "    print(cm_forest_skf_hp)\n",
        "    disp_forest_skf_hp = ConfusionMatrixDisplay(confusion_matrix=cm_forest_skf_hp, display_labels=clf_forest_skf_hp.classes_)\n",
        "    disp_forest_skf_hp.plot()\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Resultados finales\n",
        "print(f\"Random Forest - Media de Accuracy: {sum(accuracies_forest_skf_hp) / len(accuracies_forest_skf_hp):.6f}\")"
      ],
      "metadata": {
        "id": "XbTPzj9Wdx9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "mT7FcDHzx3iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un nuevo modelo KNN. No es recomendable usar un modelo ya entrenado\n",
        "clf_knn_skf_hp = KNeighborsClassifier(n_neighbors=9)"
      ],
      "metadata": {
        "id": "RQtR4I0Lx7au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista para guardar mediciones\n",
        "accuracies_knn_skf_hp = []"
      ],
      "metadata": {
        "id": "eJlMGmePx-2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo for de Stratified K Fold para KNN\n",
        "# 4 miutos con 11 segundos de ejecución\n",
        "# Accuracy Promedio 0.803233 vs 0.804902 de la Validación Simple vs 0.798037 con Hiperparámetros\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Dividimos los datos de entrenamiento y prueba\n",
        "    X_train_knn_skf_hp, X_test_knn_skf_hp = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_knn_skf_hp, y_test_knn_skf_hp = y[train_index], y[test_index]\n",
        "\n",
        "    # Escalamos los datos usando StandardScaler\n",
        "    scaler_skf_hp = StandardScaler()\n",
        "    X_train_scaled_knn_skf_hp = scaler_skf_hp.fit_transform(X_train_knn_skf_hp)  # Ajustar y transformar los datos de entrenamiento\n",
        "    X_test_scaled_knn_skf_hp = scaler_skf_hp.transform(X_test_knn_skf_hp)       # Transformar los datos de prueba\n",
        "\n",
        "    # Entrenamos el nuevo modelo\n",
        "    clf_knn_skf_hp.fit(X_train_scaled_knn_skf_hp, y_train_knn_skf_hp)\n",
        "\n",
        "    # Predecir los resultados en el conjunto de prueba\n",
        "    y_pred_knn_skf_hp = clf_knn_skf_hp.predict(X_test_scaled_knn_skf_hp)\n",
        "\n",
        "    # Calculamos la precisión\n",
        "    acc_knn_skf_hp = accuracy_score(y_test_knn_skf_hp, y_pred_knn_skf_hp)\n",
        "    accuracies_knn_skf_hp.append(acc_knn_skf_hp)\n",
        "    print(f\"Fold {fold}: Accuracy = {acc_knn_skf_hp:.6f}\")\n",
        "\n",
        "    # Creamos la Matriz de Confusión Gráfica\n",
        "    cm_knn_skf_hp = confusion_matrix(y_test_knn_skf_hp,y_pred_knn_skf_hp)\n",
        "    print(cm_knn_skf_hp)\n",
        "    disp_knn_skf_hp = ConfusionMatrixDisplay(confusion_matrix=cm_knn_skf_hp, display_labels=clf_knn_skf_hp.classes_)\n",
        "    disp_knn_skf_hp.plot()\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Resultados finais\n",
        "print(f\"KNN - Media de Accuracy: {sum(accuracies_knn_skf_hp) / len(accuracies_knn_skf_hp):.6f}\")"
      ],
      "metadata": {
        "id": "4B7v36pQyByt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística"
      ],
      "metadata": {
        "id": "U0F2d6l-6MHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializamos un nuevo modelo Random Forest. No es recomendable usar un modelo ya entrenado\n",
        "clf_reg_log_skf_hp = LogisticRegression(solver='lbfgs', random_state=42, max_iter = 1000)"
      ],
      "metadata": {
        "id": "vsEdGZjO6Lbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una lista para guardar mediciones\n",
        "accuracies_reg_log_skf_hp = []"
      ],
      "metadata": {
        "id": "aXxgKl9O6dvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ciclo for de Stratified K Fold para Random Forest\n",
        "# 3 miutos con 37 segundos\n",
        "# Accuracy Promedio 0.814311 vs 0.814384 de la Validación Simple vs 0.814384 con Hiperparametros\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Dividimos los datos de entrenamiento y prueba\n",
        "    X_train_reg_log_skf_hp, X_test_reg_log_skf_hp = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_reg_log_skf_hp, y_test_reg_log_skf_hp = y[train_index], y[test_index]\n",
        "\n",
        "    # Escalamos los datos usando StandardScaler\n",
        "    scaler_reg_log_skf_hp = StandardScaler()\n",
        "    X_train_scaled_reg_log_skf_hp = scaler_reg_log_skf_hp.fit_transform(X_train_reg_log_skf_hp)  # Ajustar y transformar los datos de entrenamiento\n",
        "    X_test_scaled_reg_log_skf_hp = scaler_reg_log_skf_hp.transform(X_test_reg_log_skf_hp)       # Transformar los datos de prueba\n",
        "\n",
        "    # Entrenamos el nuevo modelo\n",
        "    clf_reg_log_skf_hp.fit(X_train_scaled_reg_log_skf_hp, y_train_reg_log_skf_hp)\n",
        "\n",
        "    # Predecir los resultados en el conjunto de prueba\n",
        "    y_pred_reg_log_skf_hp = clf_reg_log_skf_hp.predict(X_test_scaled_reg_log_skf_hp)\n",
        "\n",
        "    # Calculamos la precisión\n",
        "    acc_reg_log_skf_hp = accuracy_score(y_test_reg_log_skf_hp, y_pred_reg_log_skf_hp)\n",
        "    accuracies_reg_log_skf_hp.append(acc_reg_log_skf_hp)\n",
        "    print(f\"Fold {fold}: Accuracy = {acc_reg_log_skf_hp:.6f}\")\n",
        "\n",
        "    # Creamos la Matriz de Confusión Gráfica\n",
        "    cm_reg_log_skf_hp = confusion_matrix(y_test_reg_log_skf_hp,y_pred_reg_log_skf_hp)\n",
        "    print(cm_reg_log_skf_hp)\n",
        "    disp_reg_log_skf_hp = ConfusionMatrixDisplay(confusion_matrix=cm_reg_log_skf_hp, display_labels=clf_reg_log_skf_hp.classes_)\n",
        "    disp_reg_log_skf_hp.plot()\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "# Resultados finais\n",
        "print(f\"Regresión Logística - Media de Accuracy: {sum(accuracies_reg_log_skf_hp) / len(accuracies_reg_log_skf_hp):.6f}\")"
      ],
      "metadata": {
        "id": "UauSyDn56yH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "\n",
        "La implementación de Stratified K Fold ha sostenido las métricas de la Validación Simple.\n",
        "\n",
        "El algoritmo de **\"Random Forest\"** sigue siendo el que mejor desempeño tiene en cuanto a los resultados. No asíen cuanto a los tiempos de ejecución."
      ],
      "metadata": {
        "id": "nX8UXRCIrr8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperparametros"
      ],
      "metadata": {
        "id": "G7kv-0JJtR_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Halving Randomized Search\n",
        "halving_cv = HalvingRandomSearchCV(model, params_grid, scoring=\"accuracy\", factor=3)\n",
        "halving_cv.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejores parametros\", halving_cv.best_params_)\n",
        "print(\"Mejor CV score\", halving_cv.best_score_)\n",
        "print(f'Accuracy del modelo = {round(accuracy_score(y_test, halving_cv.predict(X_test)), 5)}')"
      ],
      "metadata": {
        "id": "0FaoJpUDtlXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbol de Decisión"
      ],
      "metadata": {
        "id": "onLBf1dB000d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11 segundos de ejecución\n",
        "# Primer resultado:\n",
        "#   Mejores parámetros Árbol de Decisión:\n",
        "#   {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 3, 'criterion': 'gini'}\n",
        "clf_tree_hrs = DecisionTreeClassifier(random_state=42)\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Halving Randomized Search\n",
        "halving_tree = HalvingRandomSearchCV(clf_tree_hrs, param_dist, random_state=42, n_jobs=-1, factor=2)\n",
        "halving_tree.fit(X, y)\n",
        "print(\"Mejores parámetros Árbol de Decisión:\", halving_tree.best_params_)"
      ],
      "metadata": {
        "id": "rTM0zHOPzox1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "fsPFny2-1A4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 25 minutos de ejecución\n",
        "# Primer Resultado\n",
        "#   Mejores parámetros Random Forest:\n",
        "#   {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 3, 'bootstrap': True}\n",
        "clf_forest_hrs = RandomForestClassifier(random_state=42)\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "halving_forest = HalvingRandomSearchCV(clf_forest_hrs, param_dist, random_state=42, n_jobs=-1, factor=2)\n",
        "halving_forest.fit(X, y)\n",
        "print(\"Mejores parámetros Random Forest:\", halving_forest.best_params_)"
      ],
      "metadata": {
        "id": "ye6hISu11U6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "Ij1uCXkJ2le0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 segundos de ejecución\n",
        "# Primer ejecución:\n",
        "#   Mejores parámetros KNN:\n",
        "#   {'weights': 'uniform', 'n_neighbors': 10, 'metric': 'euclidean'}\n",
        "clf_knn_hrs = KNeighborsClassifier()\n",
        "param_dist = {\n",
        "    'n_neighbors': [3, 5, 10, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "halving_knn = HalvingRandomSearchCV(clf_knn_hrs, param_dist, random_state=42, n_jobs=-1, factor=2)\n",
        "halving_knn.fit(X, y)\n",
        "print(\"Mejores parámetros KNN:\", halving_knn.best_params_)"
      ],
      "metadata": {
        "id": "yx8oIzgV2rFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística"
      ],
      "metadata": {
        "id": "Cb355rvy275d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 minuto de ejcución\n",
        "# Primer Ejecución:\n",
        "#   Mejores parámetros Regresión Logística:\n",
        "#   {'solver': 'saga', 'penalty': 'l2', 'C': 0.01}\n",
        "clf_reg_log = LogisticRegression(random_state=42, max_iter=1000)\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l2', 'none'],  # 'l1' o 'elasticnet' requieren el solver 'saga'\n",
        "    'solver': ['lbfgs', 'saga']\n",
        "}\n",
        "\n",
        "halving_reg_log = HalvingRandomSearchCV(clf_reg_log, param_dist, random_state=42, n_jobs=-1, factor=2)\n",
        "halving_reg_log.fit(X, y)\n",
        "print(\"Mejores parámetros Regresión Logística:\", halving_reg_log.best_params_)"
      ],
      "metadata": {
        "id": "kJjxywYL3BW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ha implementado en el código fuente de cada celda el método **\"GridSearchCV\"**. Se ha utilizado para encontrar:\n",
        "* La profundidad óptima del arbol de decisión ha sido igual a 5 (cinco)\n",
        "* La cantidad de Árboles optima para el método de Random Forest ha sido igual a 65 (sesenta y cinco)\n",
        "* La cantidad de vecinos óptima para el método KNN ha sido 9 (nueve)"
      ],
      "metadata": {
        "id": "1a1GERy_Ybv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "c2fJktkuL5CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos X e Y para entrenar\n",
        "X_train_rd, X_test_rd, y_train_rd, y_test_rd = train_test_split(X, y, test_size=0.3, stratify= y, random_state=42)"
      ],
      "metadata": {
        "id": "zQ9zhg6sQK3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalamos X e Y\n",
        "scaler_pca = StandardScaler()\n",
        "X_train_scaled_pca = scaler_pca.fit_transform(X_train_rd)\n",
        "X_test_scaled_pca = scaler_pca.transform(X_test_rd)"
      ],
      "metadata": {
        "id": "D7niWYufMfCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementamos PCA con las variables X de train y test\n",
        "pca = PCA()\n",
        "X_train_pca = pca.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca = pca.transform(X_test_scaled_pca)"
      ],
      "metadata": {
        "id": "DJhi88jONyP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análisis de la varianza explicada para cada componente\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "explained_variance"
      ],
      "metadata": {
        "id": "GVi2X64lO645"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizamos las componentes de PCA con un numero que nos sea significativo\n",
        "pca_comp = PCA(n_components = 10)\n",
        "X_train_pca_comp = pca_comp.fit_transform(X_train_scaled_pca)\n",
        "X_test_pca_comp = pca_comp.transform(X_test_scaled_pca)"
      ],
      "metadata": {
        "id": "Te0tSXKqSlnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbol de Decisión con PCA"
      ],
      "metadata": {
        "id": "qawrIAQmMZj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el Arbol de Decisión con PCA\n",
        "# 2 segundos de ejecución\n",
        "clf_tree_pca = DecisionTreeClassifier(\n",
        "    min_samples_split = 2,\n",
        "    min_samples_leaf = 1,\n",
        "    max_depth= 3,\n",
        "    criterion = 'gini')\n",
        "\n",
        "clf_tree_pca = clf_tree_pca.fit(X_train_pca_comp, y_train_rd)"
      ],
      "metadata": {
        "id": "5BqvvGWwOfeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción PCA\n",
        "y_pred_tree_pca = clf_tree_pca.predict(X_test_pca_comp)"
      ],
      "metadata": {
        "id": "G2p0IjXiW6Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación básica del modelo\n",
        "accuracy_tree_pca = accuracy_score(y_test_rd, y_pred_tree_pca)\n",
        "print('El accuracy del modelo es:', accuracy_tree_pca)\n",
        "\n",
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_tree_pca = confusion_matrix(y_test_rd,y_pred_tree_pca)\n",
        "print(cm_tree_pca)\n",
        "disp_tree_pca = ConfusionMatrixDisplay(confusion_matrix=cm_tree_pca, display_labels=clf_tree_pca.classes_)\n",
        "disp_tree_pca.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A8r-K6vUUAPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randon Forest con PCA"
      ],
      "metadata": {
        "id": "88WGWOWeqZYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos Random Forest con PCA\n",
        "# 23 segundos de Ejecución\n",
        "clf_forest_pca = RandomForestClassifier(\n",
        "    n_estimators = 100,\n",
        "    min_samples_split = 5,\n",
        "    min_samples_leaf = 2,\n",
        "    max_features = 'log2',\n",
        "    max_depth = 3,\n",
        "    bootstrap = True,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "clf_forest_pca = clf_forest_pca.fit(X_train_pca_comp, y_train_rd)"
      ],
      "metadata": {
        "id": "m4rXJdxJqt59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción PCA\n",
        "y_pred_forest_pca = clf_forest_pca.predict(X_test_pca_comp)"
      ],
      "metadata": {
        "id": "gfoX8ItHqt5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación básica del modelo\n",
        "accuracy_forest_pca = accuracy_score(y_test_rd, y_pred_forest_pca)\n",
        "print('El accuracy del modelo es:', accuracy_forest_pca)\n",
        "\n",
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_forest_pca = confusion_matrix(y_test_rd, y_pred_forest_pca)\n",
        "print(cm_forest_pca)\n",
        "disp_forest_pca = ConfusionMatrixDisplay(confusion_matrix=cm_forest_pca, display_labels=clf_forest_pca.classes_)\n",
        "disp_forest_pca.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLEzwIIhqt5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN con PCA"
      ],
      "metadata": {
        "id": "Ks1VOqN41FGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos KNN con PCA\n",
        "# 2 segundos de ejecución\n",
        "clf_knn_pca = KNeighborsClassifier(\n",
        "    weights = 'uniform',\n",
        "    n_neighbors = 10,\n",
        "    metric = 'euclidean'\n",
        ")\n",
        "clf_knn_pca = clf_knn_pca.fit(X_train_pca_comp, y_train_rd)"
      ],
      "metadata": {
        "id": "__v12hst1W3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción PCA\n",
        "# 19 segundos de ejecución\n",
        "y_pred_knn_pca = clf_knn_pca.predict(X_test_pca_comp)"
      ],
      "metadata": {
        "id": "JXfZNWiv1W3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación básica del modelo\n",
        "accuracy_knn_pca = accuracy_score(y_test_rd, y_pred_knn_pca)\n",
        "print('El accuracy del modelo es:', accuracy_knn_pca)\n",
        "\n",
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_knn_pca = confusion_matrix(y_test_rd,y_pred_knn_pca)\n",
        "print(cm_knn_pca)\n",
        "disp_knn_pca = ConfusionMatrixDisplay(confusion_matrix=cm_knn_pca, display_labels=clf_knn_pca.classes_)\n",
        "disp_knn_pca.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmER1qiq1W3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística con PCA"
      ],
      "metadata": {
        "id": "0K4KNt_U2dFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos Regresión Logística con PCA\n",
        "# 2 segundos de ejecución\n",
        "clf_reg_log_pca = LogisticRegression(\n",
        "    solver='saga',\n",
        "    penalty='l2',\n",
        "    C=0.01,\n",
        "    random_state=42,\n",
        "    max_iter=1000  # Incrementamos max_iter por estabilidad\n",
        ")\n",
        "clf_reg_log_pca = clf_reg_log_pca.fit(X_train_pca_comp, y_train_rd)"
      ],
      "metadata": {
        "id": "WH2aBCpt2ke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción PCA\n",
        "# 19 segundos de ejecución\n",
        "y_pred_reg_log_pca = clf_reg_log_pca.predict(X_test_pca_comp)"
      ],
      "metadata": {
        "id": "vW7hWd_y2ke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación básica del modelo\n",
        "accuracy_reg_log_pca = accuracy_score(y_test_rd, y_pred_reg_log_pca)\n",
        "print('El accuracy del modelo es:', accuracy_reg_log_pca)\n",
        "\n",
        "# Creamos la Matriz de Confusión Gráfica\n",
        "cm_reg_log_pca = confusion_matrix(y_test_rd,y_pred_reg_log_pca)\n",
        "print(cm_reg_log_pca)\n",
        "disp_reg_log_pca = ConfusionMatrixDisplay(confusion_matrix=cm_reg_log_pca, display_labels=clf_reg_log_pca.classes_)\n",
        "disp_reg_log_pca.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jl--m5Kw2ke9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusiones\n",
        "La implementación de PCA nos demuestra, que reduciendo la dimensionalidad de 31 variables a 10, obtenemos rendimientos muy similares que si entrenamos los modelos sin esta técnica.\n",
        "\n",
        "Puede ser una muy buena alternativa para priorizar la performarce de los tiempos de ejecución y consumo de recursos."
      ],
      "metadata": {
        "id": "lbDJIKzx4NdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble"
      ],
      "metadata": {
        "id": "oJbx8rFda5M6"
      }
    }
  ]
}